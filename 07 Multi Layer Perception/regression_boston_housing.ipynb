{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5163cd9-69cf-4451-967c-f63b9c66157c",
   "metadata": {},
   "source": [
    "# Regression(회귀)\n",
    "\n",
    "## Boston Housing Dataset\n",
    "보스턴 주택가격 dataset은 다음과 같은 속성을 바탕으로 해당 타운 주택 가격의 중앙값을 예측하는 문제.\n",
    "- CRIM: 범죄율\n",
    "- ZN: 25,000 평방피트당 주거지역 비율\n",
    "- INDUS: 비소매 상업지구 비율\n",
    "- CHAS: 찰스강에 인접해 있는지 여부(인접:1, 아니면:0)\n",
    "- NOX: 일산화질소 농도(단위: 0.1ppm)\n",
    "- RM: 주택당 방의 수\n",
    "- AGE: 1940년 이전에 건설된 주택의 비율\n",
    "- DIS: 5개의 보스턴 직업고용센터와의 거리(가중 평균)\n",
    "- RAD: 고속도로 접근성\n",
    "- TAX: 재산세율\n",
    "- PTRATIO: 학생/교사 비율\n",
    "- B: 흑인 비율\n",
    "- LSTAT: 하위 계층 비율\n",
    "<br><br>\n",
    "- **Target**\n",
    "    - MEDV: 타운의 주택가격 중앙값(단위: 1,000달러)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a15f7f3f-2154-44ad-9049-885a9ab2e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efc0f05-071e-4c66-ac2d-ba8f2c5b225c",
   "metadata": {},
   "source": [
    "# 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "350db25b-e858-47e6-8b74-1cf7de384ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data 읽어오기\n",
    "df = pd.read_csv(\"data/boston_hosing.csv\")\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5cb9d43a-3fd5-4fe5-a2da-696f71894b25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('float32'))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X,y 분리 \n",
    "X_boston = df.drop(columns =\"MEDV\").values   # DataFrame -> ndarray\n",
    "y_boston = df[\"MEDV\"].values.reshape(-1,1)\n",
    "\n",
    "X_boston.shape, y_boston.shape\n",
    "X_boston.dtype, y_boston.dtype\n",
    "\n",
    "# dtype변경   - linear 계산시 dtype 맞추기?\n",
    "X_boston = X_boston.astype(\"float32\")\n",
    "y_boston = y_boston.astype(\"float32\")\n",
    "X_boston.dtype, y_boston.dtype\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "75751aa8-e777-4c1e-bbec-9d44eb8dcb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 분리 \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_boston, y_boston, test_size= 0.2, random_state= 0)\n",
    "# 회귀니까 stratify 지정안함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3f1a9e79-7c11-4607-91e6-b8d436363db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling  (Feature간의 scaling 값의 범위 통일)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled= scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b0a36740-70d0-4a80-ba96-1eff2aa9b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 생성  - TensorDataset\n",
    "\n",
    "trainset = TensorDataset(torch.tensor(X_train_scaled), torch.tensor(y_train))\n",
    "testset = TensorDataset(torch.tensor(X_test_scaled), torch.tensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "217fe1d6-1b63-47cb-a7cd-e9a2b40f81ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 수  2 1\n"
     ]
    }
   ],
   "source": [
    "# DataLoader 생성\n",
    "\n",
    "train_loader = DataLoader(trainset, 200, shuffle= True, drop_last= True)\n",
    "\n",
    "test_loader = DataLoader(testset, len(testset)) # train과 같은 수로 batch 줄 필요 없음\n",
    "\n",
    "\n",
    "print(\"step 수 \", len(train_loader), len(test_loader)) # step : 한 epoch을 도는 데 걸리는 batch 수 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d8ec1-2d08-4633-aed6-e21c2e454673",
   "metadata": {},
   "source": [
    "# 2. 모델 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7cab98b4-7bba-4565-b7ad-93363e1a9188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(404, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c1f715d3-41d7-4b6d-9342-506b3a4420f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BostonModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # 1. 부모 클래스의 __init__() 호출해 초기화 (필수)\n",
    "        super().__init__()\n",
    "        # instance 변수 초기화 : forward()에서 사용할 함수들(Layer) 초기화\n",
    "        self.lr1 = nn.Linear(in_features= 13, out_features= 32)\n",
    "        self.lr2 = nn.Linear(32,16)\n",
    "        self.lr3 = nn.Linear(16,1)\n",
    "        self.relu = nn.ReLU() # FCL(nn.Linear)로 구성된 딥러닝 모델 -> 비선형성 주기\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.lr1(X)\n",
    "        out = self.relu(out)\n",
    "        out = self.lr2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.lr3(out)  \n",
    "        #추정할 값의 scale에 따라 activation 함수 사용 가능 \n",
    "        # 0-1로 압축 : logistic 함수(nn.Sigmoid), -1~1로 압축: hyperbolic tangent(nn.Tanh)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a2298c7c-956f-44a3-a0f3-60ed69b88b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 instance 생성\n",
    "model = BostonModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3fedc54e-4d66-4908-9b6f-8feabeb7ff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BostonModel(\n",
      "  (lr1): Linear(in_features=13, out_features=32, bias=True)\n",
      "  (lr2): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (lr3): Linear(in_features=16, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 구조 확인 \n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7df7f3f3-6d82-4727-ae87-e2673a1efa99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BostonModel                              [100, 1]                  --\n",
       "├─Linear: 1-1                            [100, 32]                 448\n",
       "├─ReLU: 1-2                              [100, 32]                 --\n",
       "├─Linear: 1-3                            [100, 16]                 528\n",
       "├─ReLU: 1-4                              [100, 16]                 --\n",
       "├─Linear: 1-5                            [100, 1]                  17\n",
       "==========================================================================================\n",
       "Total params: 993\n",
       "Trainable params: 993\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.10\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.04\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,(100,13)) # (batch, feature 수 )\n",
    "\n",
    "# 파라미터 수 \n",
    "# 13*32 + 32 = 448\n",
    "# 32*16 + 16(bias) = 528\n",
    "\n",
    "# 일대일 전연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c369807-9e82-46b5-883e-546a13276050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000001F128C92F80>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델에서 layer 함수를 조회\n",
    "layer1 = model.lr1\n",
    "w1= layer1.weight\n",
    "b1 = layer1.bias\n",
    "\n",
    "# 모델의 전체 weight와 parameter들 -> optimizer에 모델의 파라미터 전달 \n",
    "## generator : 반복할 때마다 layer 순서대로 weight, bias 전달\n",
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7eef7e2-1992-4d79-9279-8b201fca9cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.dtype, b1.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7410db-19b0-4ee5-9b63-2241fb25cbc6",
   "metadata": {},
   "source": [
    "#  3. Train - 학습 +검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "282514bc-1aeb-4d90-b818-661e77dd64b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 정의 \n",
    "EPOCHS = 1000\n",
    "LR = 0.001     # 학습율 ; optimizer에 설정 \n",
    "\n",
    "# model, loss 함수, optimizer 준비\n",
    "model = BostonModel().to(device) # device로 옮기기\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(\n",
    "    model.parameters(),  \n",
    "    lr = LR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c091a43e-86cf-4d8d-b778-a40b593023d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0001/1000 train loss : 595.2448120117188 valid loss : 565.4071044921875]\n",
      "[0002/1000 train loss : 585.9095153808594 valid loss : 555.9436645507812]\n",
      "[0003/1000 train loss : 575.192626953125 valid loss : 545.0020141601562]\n",
      "[0004/1000 train loss : 563.1127014160156 valid loss : 531.947998046875]\n",
      "[0005/1000 train loss : 545.4125061035156 valid loss : 515.2933349609375]\n",
      "[0006/1000 train loss : 528.6676940917969 valid loss : 497.0140075683594]\n",
      "[0007/1000 train loss : 506.63575744628906 valid loss : 478.1819152832031]\n",
      "[0008/1000 train loss : 486.9810791015625 valid loss : 458.66363525390625]\n",
      "[0009/1000 train loss : 456.0754852294922 valid loss : 438.7998352050781]\n",
      "[0010/1000 train loss : 440.2146759033203 valid loss : 418.537353515625]\n",
      "[0011/1000 train loss : 416.29296875 valid loss : 398.17633056640625]\n",
      "[0012/1000 train loss : 395.63584899902344 valid loss : 377.76873779296875]\n",
      "[0013/1000 train loss : 372.5266418457031 valid loss : 357.7056579589844]\n",
      "[0014/1000 train loss : 352.1427001953125 valid loss : 338.0660705566406]\n",
      "[0015/1000 train loss : 328.9377136230469 valid loss : 319.0730285644531]\n",
      "[0016/1000 train loss : 307.0343780517578 valid loss : 300.7333679199219]\n",
      "[0017/1000 train loss : 281.50201416015625 valid loss : 283.3904724121094]\n",
      "[0018/1000 train loss : 268.2450180053711 valid loss : 266.8520202636719]\n",
      "[0019/1000 train loss : 249.85865020751953 valid loss : 251.17327880859375]\n",
      "[0020/1000 train loss : 232.15882873535156 valid loss : 236.52598571777344]\n",
      "[0021/1000 train loss : 215.95946502685547 valid loss : 222.84019470214844]\n",
      "[0022/1000 train loss : 202.0062255859375 valid loss : 210.1414337158203]\n",
      "[0023/1000 train loss : 183.1265640258789 valid loss : 198.5867462158203]\n",
      "[0024/1000 train loss : 174.69004821777344 valid loss : 187.86825561523438]\n",
      "[0025/1000 train loss : 163.49234771728516 valid loss : 177.99122619628906]\n",
      "[0026/1000 train loss : 151.00718688964844 valid loss : 169.08865356445312]\n",
      "[0027/1000 train loss : 140.86278533935547 valid loss : 160.94569396972656]\n",
      "[0028/1000 train loss : 133.71353912353516 valid loss : 153.3773193359375]\n",
      "[0029/1000 train loss : 124.33167266845703 valid loss : 146.57513427734375]\n",
      "[0030/1000 train loss : 118.01541519165039 valid loss : 140.24612426757812]\n",
      "[0031/1000 train loss : 112.47782516479492 valid loss : 134.4257049560547]\n",
      "[0032/1000 train loss : 103.17243957519531 valid loss : 129.14573669433594]\n",
      "[0033/1000 train loss : 99.92072677612305 valid loss : 124.2528305053711]\n",
      "[0034/1000 train loss : 95.3521614074707 valid loss : 119.71533203125]\n",
      "[0035/1000 train loss : 91.15762710571289 valid loss : 115.47945404052734]\n",
      "[0036/1000 train loss : 85.3981704711914 valid loss : 111.68025207519531]\n",
      "[0037/1000 train loss : 82.41227340698242 valid loss : 108.07328033447266]\n",
      "[0038/1000 train loss : 78.47269058227539 valid loss : 104.7451171875]\n",
      "[0039/1000 train loss : 75.66203308105469 valid loss : 101.60284423828125]\n",
      "[0040/1000 train loss : 70.64904403686523 valid loss : 98.76509094238281]\n",
      "[0041/1000 train loss : 69.0247917175293 valid loss : 96.05518341064453]\n",
      "[0042/1000 train loss : 66.9298267364502 valid loss : 93.47181701660156]\n",
      "[0043/1000 train loss : 64.06643676757812 valid loss : 91.05865478515625]\n",
      "[0044/1000 train loss : 61.893394470214844 valid loss : 88.82640075683594]\n",
      "[0045/1000 train loss : 59.43746376037598 valid loss : 86.69802856445312]\n",
      "[0046/1000 train loss : 57.6734619140625 valid loss : 84.7173843383789]\n",
      "[0047/1000 train loss : 55.48602867126465 valid loss : 82.8082504272461]\n",
      "[0048/1000 train loss : 54.13238525390625 valid loss : 81.0272216796875]\n",
      "[0049/1000 train loss : 49.72846603393555 valid loss : 79.44732666015625]\n",
      "[0050/1000 train loss : 50.94377136230469 valid loss : 77.81926727294922]\n",
      "[0051/1000 train loss : 49.443050384521484 valid loss : 76.30353546142578]\n",
      "[0052/1000 train loss : 47.89044189453125 valid loss : 74.89337921142578]\n",
      "[0053/1000 train loss : 46.869733810424805 valid loss : 73.4880599975586]\n",
      "[0054/1000 train loss : 45.66194534301758 valid loss : 72.16619110107422]\n",
      "[0055/1000 train loss : 44.056419372558594 valid loss : 70.91866302490234]\n",
      "[0056/1000 train loss : 43.36461639404297 valid loss : 69.7113037109375]\n",
      "[0057/1000 train loss : 41.990848541259766 valid loss : 68.58010864257812]\n",
      "[0058/1000 train loss : 41.06872749328613 valid loss : 67.49380493164062]\n",
      "[0059/1000 train loss : 39.779680252075195 valid loss : 66.48606872558594]\n",
      "[0060/1000 train loss : 38.970008850097656 valid loss : 65.4957046508789]\n",
      "[0061/1000 train loss : 38.44891357421875 valid loss : 64.53970336914062]\n",
      "[0062/1000 train loss : 37.50403594970703 valid loss : 63.63636779785156]\n",
      "[0063/1000 train loss : 36.89002990722656 valid loss : 62.753902435302734]\n",
      "[0064/1000 train loss : 36.025840759277344 valid loss : 61.932281494140625]\n",
      "[0065/1000 train loss : 35.41774368286133 valid loss : 61.136680603027344]\n",
      "[0066/1000 train loss : 34.61064147949219 valid loss : 60.357051849365234]\n",
      "[0067/1000 train loss : 33.674617767333984 valid loss : 59.594966888427734]\n",
      "[0068/1000 train loss : 33.22262191772461 valid loss : 58.8968391418457]\n",
      "[0069/1000 train loss : 32.79029083251953 valid loss : 58.205814361572266]\n",
      "[0070/1000 train loss : 32.3565092086792 valid loss : 57.5252571105957]\n",
      "[0071/1000 train loss : 31.6182918548584 valid loss : 56.88775634765625]\n",
      "[0072/1000 train loss : 31.153703689575195 valid loss : 56.26302719116211]\n",
      "[0073/1000 train loss : 30.55873203277588 valid loss : 55.68417739868164]\n",
      "[0074/1000 train loss : 30.2186336517334 valid loss : 55.09319305419922]\n",
      "[0075/1000 train loss : 29.82074546813965 valid loss : 54.575157165527344]\n",
      "[0076/1000 train loss : 29.272650718688965 valid loss : 54.02980422973633]\n",
      "[0077/1000 train loss : 28.98826503753662 valid loss : 53.487552642822266]\n",
      "[0078/1000 train loss : 28.399128913879395 valid loss : 52.974246978759766]\n",
      "[0079/1000 train loss : 28.163247108459473 valid loss : 52.50628662109375]\n",
      "[0080/1000 train loss : 27.75441837310791 valid loss : 52.00822448730469]\n",
      "[0081/1000 train loss : 27.59721088409424 valid loss : 51.542503356933594]\n",
      "[0082/1000 train loss : 26.98490619659424 valid loss : 51.118865966796875]\n",
      "[0083/1000 train loss : 26.847952842712402 valid loss : 50.66749954223633]\n",
      "[0084/1000 train loss : 26.216886520385742 valid loss : 50.2796516418457]\n",
      "[0085/1000 train loss : 26.381975173950195 valid loss : 49.855201721191406]\n",
      "[0086/1000 train loss : 26.13149642944336 valid loss : 49.46574783325195]\n",
      "[0087/1000 train loss : 25.763593673706055 valid loss : 49.05844497680664]\n",
      "[0088/1000 train loss : 25.446864128112793 valid loss : 48.68915557861328]\n",
      "[0089/1000 train loss : 25.30760097503662 valid loss : 48.336673736572266]\n",
      "[0090/1000 train loss : 24.542733192443848 valid loss : 47.986114501953125]\n",
      "[0091/1000 train loss : 24.767038345336914 valid loss : 47.649471282958984]\n",
      "[0092/1000 train loss : 24.500038146972656 valid loss : 47.31620407104492]\n",
      "[0093/1000 train loss : 24.383490562438965 valid loss : 46.99998474121094]\n",
      "[0094/1000 train loss : 24.21208620071411 valid loss : 46.64674377441406]\n",
      "[0095/1000 train loss : 21.795620918273926 valid loss : 46.473670959472656]\n",
      "[0096/1000 train loss : 23.71962833404541 valid loss : 46.12760925292969]\n",
      "[0097/1000 train loss : 23.50483798980713 valid loss : 45.823707580566406]\n",
      "[0098/1000 train loss : 23.371004104614258 valid loss : 45.521183013916016]\n",
      "[0099/1000 train loss : 23.119608879089355 valid loss : 45.254364013671875]\n",
      "[0100/1000 train loss : 22.992897033691406 valid loss : 44.90825653076172]\n",
      "[0101/1000 train loss : 22.76505184173584 valid loss : 44.596920013427734]\n",
      "[0102/1000 train loss : 22.35689640045166 valid loss : 44.325199127197266]\n",
      "[0103/1000 train loss : 21.95319366455078 valid loss : 44.08282470703125]\n",
      "[0104/1000 train loss : 22.292595863342285 valid loss : 43.79813003540039]\n",
      "[0105/1000 train loss : 22.144238471984863 valid loss : 43.52603530883789]\n",
      "[0106/1000 train loss : 22.009170532226562 valid loss : 43.27873229980469]\n",
      "[0107/1000 train loss : 21.83444118499756 valid loss : 43.03254318237305]\n",
      "[0108/1000 train loss : 21.69038677215576 valid loss : 42.781349182128906]\n",
      "[0109/1000 train loss : 21.396292686462402 valid loss : 42.531883239746094]\n",
      "[0110/1000 train loss : 21.364346504211426 valid loss : 42.29231643676758]\n",
      "[0111/1000 train loss : 21.19642448425293 valid loss : 42.07331848144531]\n",
      "[0112/1000 train loss : 20.95394229888916 valid loss : 41.88600540161133]\n",
      "[0113/1000 train loss : 21.03019428253174 valid loss : 41.660438537597656]\n",
      "[0114/1000 train loss : 20.704526901245117 valid loss : 41.439083099365234]\n",
      "[0115/1000 train loss : 20.511794090270996 valid loss : 41.19430160522461]\n",
      "[0116/1000 train loss : 20.599888801574707 valid loss : 40.974998474121094]\n",
      "[0117/1000 train loss : 20.49625301361084 valid loss : 40.78969955444336]\n",
      "[0118/1000 train loss : 20.179633617401123 valid loss : 40.533721923828125]\n",
      "[0119/1000 train loss : 20.06605339050293 valid loss : 40.37822341918945]\n",
      "[0120/1000 train loss : 20.146573066711426 valid loss : 40.21601486206055]\n",
      "[0121/1000 train loss : 20.050564765930176 valid loss : 40.03419876098633]\n",
      "[0122/1000 train loss : 19.896241188049316 valid loss : 39.8390998840332]\n",
      "[0123/1000 train loss : 19.708552360534668 valid loss : 39.6814079284668]\n",
      "[0124/1000 train loss : 19.711474418640137 valid loss : 39.4840202331543]\n",
      "[0125/1000 train loss : 19.535810470581055 valid loss : 39.30219650268555]\n",
      "[0126/1000 train loss : 19.372121810913086 valid loss : 39.143226623535156]\n",
      "[0127/1000 train loss : 19.256613731384277 valid loss : 38.95274353027344]\n",
      "[0128/1000 train loss : 19.226913452148438 valid loss : 38.762142181396484]\n",
      "[0129/1000 train loss : 19.056530952453613 valid loss : 38.57966995239258]\n",
      "[0130/1000 train loss : 18.900482177734375 valid loss : 38.40406799316406]\n",
      "[0131/1000 train loss : 18.71715545654297 valid loss : 38.284523010253906]\n",
      "[0132/1000 train loss : 18.53488063812256 valid loss : 38.11497497558594]\n",
      "[0133/1000 train loss : 18.52882432937622 valid loss : 37.953277587890625]\n",
      "[0134/1000 train loss : 18.601360321044922 valid loss : 37.7596321105957]\n",
      "[0135/1000 train loss : 18.303019523620605 valid loss : 37.58522033691406]\n",
      "[0136/1000 train loss : 18.31370735168457 valid loss : 37.409278869628906]\n",
      "[0137/1000 train loss : 17.72187042236328 valid loss : 37.211158752441406]\n",
      "[0138/1000 train loss : 18.126078605651855 valid loss : 37.07009506225586]\n",
      "[0139/1000 train loss : 17.9644718170166 valid loss : 36.964111328125]\n",
      "[0140/1000 train loss : 17.99689769744873 valid loss : 36.80223846435547]\n",
      "[0141/1000 train loss : 17.56299591064453 valid loss : 36.69259262084961]\n",
      "[0142/1000 train loss : 17.828103065490723 valid loss : 36.52313995361328]\n",
      "[0143/1000 train loss : 17.55986499786377 valid loss : 36.31781768798828]\n",
      "[0144/1000 train loss : 17.628785133361816 valid loss : 36.17271423339844]\n",
      "[0145/1000 train loss : 17.348246574401855 valid loss : 36.060302734375]\n",
      "[0146/1000 train loss : 17.441465377807617 valid loss : 35.95586013793945]\n",
      "[0147/1000 train loss : 17.24831485748291 valid loss : 35.776668548583984]\n",
      "[0148/1000 train loss : 16.90559482574463 valid loss : 35.60115432739258]\n",
      "[0149/1000 train loss : 16.920714378356934 valid loss : 35.44730758666992]\n",
      "[0150/1000 train loss : 17.09691333770752 valid loss : 35.32500457763672]\n",
      "[0151/1000 train loss : 16.97892189025879 valid loss : 35.194358825683594]\n",
      "[0152/1000 train loss : 16.758829593658447 valid loss : 35.02876663208008]\n",
      "[0153/1000 train loss : 16.236858367919922 valid loss : 34.8143310546875]\n",
      "[0154/1000 train loss : 16.599217414855957 valid loss : 34.68479537963867]\n",
      "[0155/1000 train loss : 16.589929580688477 valid loss : 34.575191497802734]\n",
      "[0156/1000 train loss : 16.441808700561523 valid loss : 34.438228607177734]\n",
      "[0157/1000 train loss : 16.289174556732178 valid loss : 34.27900314331055]\n",
      "[0158/1000 train loss : 16.32761526107788 valid loss : 34.197601318359375]\n",
      "[0159/1000 train loss : 15.43314790725708 valid loss : 34.201507568359375]\n",
      "[0160/1000 train loss : 16.173365116119385 valid loss : 34.02849578857422]\n",
      "[0161/1000 train loss : 16.03942346572876 valid loss : 33.904930114746094]\n",
      "[0162/1000 train loss : 15.829950332641602 valid loss : 33.7499885559082]\n",
      "[0163/1000 train loss : 15.88624382019043 valid loss : 33.6323356628418]\n",
      "[0164/1000 train loss : 15.781604290008545 valid loss : 33.529266357421875]\n",
      "[0165/1000 train loss : 15.634438037872314 valid loss : 33.40340042114258]\n",
      "[0166/1000 train loss : 15.607991695404053 valid loss : 33.256866455078125]\n",
      "[0167/1000 train loss : 13.901613235473633 valid loss : 33.306610107421875]\n",
      "[0168/1000 train loss : 15.488502025604248 valid loss : 33.14164352416992]\n",
      "[0169/1000 train loss : 15.46080207824707 valid loss : 33.03614044189453]\n",
      "[0170/1000 train loss : 15.167600631713867 valid loss : 32.92953872680664]\n",
      "[0171/1000 train loss : 15.146372318267822 valid loss : 32.74666976928711]\n",
      "[0172/1000 train loss : 15.121158599853516 valid loss : 32.64862060546875]\n",
      "[0173/1000 train loss : 15.110732555389404 valid loss : 32.543399810791016]\n",
      "[0174/1000 train loss : 14.68037223815918 valid loss : 32.363555908203125]\n",
      "[0175/1000 train loss : 14.878514766693115 valid loss : 32.294090270996094]\n",
      "[0176/1000 train loss : 14.893049716949463 valid loss : 32.20689392089844]\n",
      "[0177/1000 train loss : 14.515497207641602 valid loss : 32.096900939941406]\n",
      "[0178/1000 train loss : 14.751620769500732 valid loss : 31.926284790039062]\n",
      "[0179/1000 train loss : 14.629926681518555 valid loss : 31.81444549560547]\n",
      "[0180/1000 train loss : 14.615894794464111 valid loss : 31.705284118652344]\n",
      "[0181/1000 train loss : 14.239588260650635 valid loss : 31.68194007873535]\n",
      "[0182/1000 train loss : 14.43530797958374 valid loss : 31.548086166381836]\n",
      "[0183/1000 train loss : 14.337435245513916 valid loss : 31.423215866088867]\n",
      "[0184/1000 train loss : 14.195315837860107 valid loss : 31.373281478881836]\n",
      "[0185/1000 train loss : 13.805850505828857 valid loss : 31.267362594604492]\n",
      "[0186/1000 train loss : 14.178978443145752 valid loss : 31.168567657470703]\n",
      "[0187/1000 train loss : 13.90244197845459 valid loss : 31.11740493774414]\n",
      "[0188/1000 train loss : 14.009478569030762 valid loss : 31.114669799804688]\n",
      "[0189/1000 train loss : 13.569909572601318 valid loss : 30.8410701751709]\n",
      "[0190/1000 train loss : 13.819305896759033 valid loss : 30.737632751464844]\n",
      "[0191/1000 train loss : 13.85727596282959 valid loss : 30.684463500976562]\n",
      "[0192/1000 train loss : 13.72265338897705 valid loss : 30.538835525512695]\n",
      "[0193/1000 train loss : 13.636244773864746 valid loss : 30.494829177856445]\n",
      "[0194/1000 train loss : 13.48438024520874 valid loss : 30.346893310546875]\n",
      "[0195/1000 train loss : 13.634587287902832 valid loss : 30.259531021118164]\n",
      "[0196/1000 train loss : 12.783718585968018 valid loss : 30.03167152404785]\n",
      "[0197/1000 train loss : 13.344248294830322 valid loss : 30.00309944152832]\n",
      "[0198/1000 train loss : 13.31740427017212 valid loss : 29.92705726623535]\n",
      "[0199/1000 train loss : 13.265789985656738 valid loss : 29.878583908081055]\n",
      "[0200/1000 train loss : 13.285181522369385 valid loss : 29.78008270263672]\n",
      "[0201/1000 train loss : 13.161514282226562 valid loss : 29.73732566833496]\n",
      "[0202/1000 train loss : 12.9605073928833 valid loss : 29.601797103881836]\n",
      "[0203/1000 train loss : 12.997560501098633 valid loss : 29.492456436157227]\n",
      "[0204/1000 train loss : 13.016609191894531 valid loss : 29.436412811279297]\n",
      "[0205/1000 train loss : 12.94180154800415 valid loss : 29.380062103271484]\n",
      "[0206/1000 train loss : 12.811193466186523 valid loss : 29.325458526611328]\n",
      "[0207/1000 train loss : 12.812613010406494 valid loss : 29.22896385192871]\n",
      "[0208/1000 train loss : 12.70545244216919 valid loss : 29.015708923339844]\n",
      "[0209/1000 train loss : 12.684814453125 valid loss : 28.8948974609375]\n",
      "[0210/1000 train loss : 12.683024883270264 valid loss : 28.928632736206055]\n",
      "[0211/1000 train loss : 12.628961563110352 valid loss : 28.88058090209961]\n",
      "[0212/1000 train loss : 11.996805667877197 valid loss : 28.825740814208984]\n",
      "[0213/1000 train loss : 12.504939556121826 valid loss : 28.71387481689453]\n",
      "[0214/1000 train loss : 11.746848583221436 valid loss : 28.48440933227539]\n",
      "[0215/1000 train loss : 12.37278413772583 valid loss : 28.450681686401367]\n",
      "[0216/1000 train loss : 12.32149887084961 valid loss : 28.34623908996582]\n",
      "[0217/1000 train loss : 12.179043292999268 valid loss : 28.224267959594727]\n",
      "[0218/1000 train loss : 11.471235275268555 valid loss : 28.040817260742188]\n",
      "[0219/1000 train loss : 12.040390968322754 valid loss : 28.016857147216797]\n",
      "[0220/1000 train loss : 12.013096332550049 valid loss : 27.95682144165039]\n",
      "[0221/1000 train loss : 11.976617336273193 valid loss : 27.925077438354492]\n",
      "[0222/1000 train loss : 11.9462308883667 valid loss : 27.91657257080078]\n",
      "[0223/1000 train loss : 11.992306232452393 valid loss : 27.838029861450195]\n",
      "[0224/1000 train loss : 11.920633316040039 valid loss : 27.72024917602539]\n",
      "[0225/1000 train loss : 11.30740213394165 valid loss : 27.85272789001465]\n",
      "[0226/1000 train loss : 11.872009754180908 valid loss : 27.788236618041992]\n",
      "[0227/1000 train loss : 11.82543659210205 valid loss : 27.664243698120117]\n",
      "[0228/1000 train loss : 11.707541942596436 valid loss : 27.515365600585938]\n",
      "[0229/1000 train loss : 11.675055980682373 valid loss : 27.410118103027344]\n",
      "[0230/1000 train loss : 11.689055919647217 valid loss : 27.371997833251953]\n",
      "[0231/1000 train loss : 11.614083290100098 valid loss : 27.2916202545166]\n",
      "[0232/1000 train loss : 11.471455574035645 valid loss : 27.24921989440918]\n",
      "[0233/1000 train loss : 11.404459953308105 valid loss : 27.202131271362305]\n",
      "[0234/1000 train loss : 11.384853839874268 valid loss : 27.019481658935547]\n",
      "[0235/1000 train loss : 11.472551584243774 valid loss : 26.916053771972656]\n",
      "[0236/1000 train loss : 11.470532417297363 valid loss : 26.942974090576172]\n",
      "[0237/1000 train loss : 11.272544384002686 valid loss : 26.79755401611328]\n",
      "[0238/1000 train loss : 11.301586151123047 valid loss : 26.6986141204834]\n",
      "[0239/1000 train loss : 11.291891098022461 valid loss : 26.740463256835938]\n",
      "[0240/1000 train loss : 10.961266994476318 valid loss : 26.74728012084961]\n",
      "[0241/1000 train loss : 11.130010604858398 valid loss : 26.650053024291992]\n",
      "[0242/1000 train loss : 11.075777053833008 valid loss : 26.553964614868164]\n",
      "[0243/1000 train loss : 11.133987426757812 valid loss : 26.57448959350586]\n",
      "[0244/1000 train loss : 11.107015132904053 valid loss : 26.400192260742188]\n",
      "[0245/1000 train loss : 11.02007246017456 valid loss : 26.2158145904541]\n",
      "[0246/1000 train loss : 10.946185111999512 valid loss : 26.271947860717773]\n",
      "[0247/1000 train loss : 11.051602363586426 valid loss : 26.18981170654297]\n",
      "[0248/1000 train loss : 10.104122161865234 valid loss : 26.00939178466797]\n",
      "[0249/1000 train loss : 10.850263118743896 valid loss : 25.947032928466797]\n",
      "[0250/1000 train loss : 10.789853572845459 valid loss : 25.8531436920166]\n",
      "[0251/1000 train loss : 10.770841121673584 valid loss : 25.832565307617188]\n",
      "[0252/1000 train loss : 10.224495887756348 valid loss : 25.943328857421875]\n",
      "[0253/1000 train loss : 10.710599422454834 valid loss : 25.843280792236328]\n",
      "[0254/1000 train loss : 10.675664901733398 valid loss : 25.78981590270996]\n",
      "[0255/1000 train loss : 10.630109786987305 valid loss : 25.65358543395996]\n",
      "[0256/1000 train loss : 10.576613903045654 valid loss : 25.613710403442383]\n",
      "[0257/1000 train loss : 10.48056697845459 valid loss : 25.635961532592773]\n",
      "[0258/1000 train loss : 10.552149295806885 valid loss : 25.492761611938477]\n",
      "[0259/1000 train loss : 10.532667636871338 valid loss : 25.469284057617188]\n",
      "[0260/1000 train loss : 10.466520309448242 valid loss : 25.44062614440918]\n",
      "[0261/1000 train loss : 10.448389530181885 valid loss : 25.27346420288086]\n",
      "[0262/1000 train loss : 10.456233501434326 valid loss : 25.34900665283203]\n",
      "[0263/1000 train loss : 10.271512031555176 valid loss : 25.153196334838867]\n",
      "[0264/1000 train loss : 10.370034217834473 valid loss : 25.18790054321289]\n",
      "[0265/1000 train loss : 10.304890632629395 valid loss : 25.20242691040039]\n",
      "[0266/1000 train loss : 10.09066128730774 valid loss : 25.11266326904297]\n",
      "[0267/1000 train loss : 10.183543682098389 valid loss : 25.148738861083984]\n",
      "[0268/1000 train loss : 10.27743673324585 valid loss : 25.170297622680664]\n",
      "[0269/1000 train loss : 9.946925640106201 valid loss : 25.009305953979492]\n",
      "[0270/1000 train loss : 10.16824197769165 valid loss : 24.955669403076172]\n",
      "[0271/1000 train loss : 10.098735332489014 valid loss : 25.009971618652344]\n",
      "[0272/1000 train loss : 10.099459171295166 valid loss : 24.75678062438965]\n",
      "[0273/1000 train loss : 9.841397285461426 valid loss : 24.917264938354492]\n",
      "[0274/1000 train loss : 10.047625064849854 valid loss : 24.764509201049805]\n",
      "[0275/1000 train loss : 9.796981811523438 valid loss : 24.69704246520996]\n",
      "[0276/1000 train loss : 9.988280296325684 valid loss : 24.52958869934082]\n",
      "[0277/1000 train loss : 9.917105674743652 valid loss : 24.56386375427246]\n",
      "[0278/1000 train loss : 9.909910678863525 valid loss : 24.437057495117188]\n",
      "[0279/1000 train loss : 9.864873886108398 valid loss : 24.44348907470703]\n",
      "[0280/1000 train loss : 9.798937320709229 valid loss : 24.389020919799805]\n",
      "[0281/1000 train loss : 9.858031749725342 valid loss : 24.496898651123047]\n",
      "[0282/1000 train loss : 9.761027812957764 valid loss : 24.35385513305664]\n",
      "[0283/1000 train loss : 9.616068840026855 valid loss : 24.34456443786621]\n",
      "[0284/1000 train loss : 9.748383522033691 valid loss : 24.2705078125]\n",
      "[0285/1000 train loss : 9.58960747718811 valid loss : 24.165931701660156]\n",
      "[0286/1000 train loss : 9.750488758087158 valid loss : 24.111499786376953]\n",
      "[0287/1000 train loss : 9.665087223052979 valid loss : 24.01425552368164]\n",
      "[0288/1000 train loss : 9.580609798431396 valid loss : 24.12646484375]\n",
      "[0289/1000 train loss : 9.602110147476196 valid loss : 23.96661949157715]\n",
      "[0290/1000 train loss : 9.553436756134033 valid loss : 24.004274368286133]\n",
      "[0291/1000 train loss : 9.510390281677246 valid loss : 23.963457107543945]\n",
      "[0292/1000 train loss : 9.52261757850647 valid loss : 23.870620727539062]\n",
      "[0293/1000 train loss : 9.489013671875 valid loss : 23.94158172607422]\n",
      "[0294/1000 train loss : 9.41800832748413 valid loss : 23.859329223632812]\n",
      "[0295/1000 train loss : 9.40165662765503 valid loss : 23.793989181518555]\n",
      "[0296/1000 train loss : 9.379348754882812 valid loss : 23.757709503173828]\n",
      "[0297/1000 train loss : 9.337255477905273 valid loss : 23.715923309326172]\n",
      "[0298/1000 train loss : 9.21924877166748 valid loss : 23.517091751098633]\n",
      "[0299/1000 train loss : 9.1987943649292 valid loss : 23.49920082092285]\n",
      "[0300/1000 train loss : 9.294318199157715 valid loss : 23.50972557067871]\n",
      "[0301/1000 train loss : 8.346418857574463 valid loss : 23.601211547851562]\n",
      "[0302/1000 train loss : 9.238693475723267 valid loss : 23.622316360473633]\n",
      "[0303/1000 train loss : 9.251919031143188 valid loss : 23.406635284423828]\n",
      "[0304/1000 train loss : 9.223305702209473 valid loss : 23.433856964111328]\n",
      "[0305/1000 train loss : 9.211721897125244 valid loss : 23.343915939331055]\n",
      "[0306/1000 train loss : 9.090737342834473 valid loss : 23.364517211914062]\n",
      "[0307/1000 train loss : 9.066355228424072 valid loss : 23.424623489379883]\n",
      "[0308/1000 train loss : 9.135493278503418 valid loss : 23.41606903076172]\n",
      "[0309/1000 train loss : 9.019879817962646 valid loss : 23.32284927368164]\n",
      "[0310/1000 train loss : 9.015293598175049 valid loss : 23.305498123168945]\n",
      "[0311/1000 train loss : 9.019676446914673 valid loss : 23.13173484802246]\n",
      "[0312/1000 train loss : 9.082636594772339 valid loss : 23.196611404418945]\n",
      "[0313/1000 train loss : 8.118000030517578 valid loss : 23.018444061279297]\n",
      "[0314/1000 train loss : 8.998626708984375 valid loss : 22.893295288085938]\n",
      "[0315/1000 train loss : 9.02492642402649 valid loss : 23.02099609375]\n",
      "[0316/1000 train loss : 8.835142612457275 valid loss : 23.095109939575195]\n",
      "[0317/1000 train loss : 8.929647445678711 valid loss : 23.005050659179688]\n",
      "[0318/1000 train loss : 8.928905010223389 valid loss : 22.847963333129883]\n",
      "[0319/1000 train loss : 8.851356506347656 valid loss : 22.902969360351562]\n",
      "[0320/1000 train loss : 8.90944528579712 valid loss : 22.834169387817383]\n",
      "[0321/1000 train loss : 8.766839981079102 valid loss : 22.92743492126465]\n",
      "[0322/1000 train loss : 8.800711154937744 valid loss : 22.909894943237305]\n",
      "[0323/1000 train loss : 8.819196939468384 valid loss : 22.865772247314453]\n",
      "[0324/1000 train loss : 8.773446083068848 valid loss : 22.816049575805664]\n",
      "[0325/1000 train loss : 8.6896390914917 valid loss : 22.814979553222656]\n",
      "[0326/1000 train loss : 8.741867065429688 valid loss : 22.787717819213867]\n",
      "[0327/1000 train loss : 8.713367938995361 valid loss : 22.74323844909668]\n",
      "[0328/1000 train loss : 8.770819664001465 valid loss : 22.898046493530273]\n",
      "[0329/1000 train loss : 8.673476219177246 valid loss : 22.83855628967285]\n",
      "[0330/1000 train loss : 8.619643449783325 valid loss : 22.69049835205078]\n",
      "[0331/1000 train loss : 8.611302137374878 valid loss : 22.737096786499023]\n",
      "[0332/1000 train loss : 8.609504461288452 valid loss : 22.70488929748535]\n",
      "[0333/1000 train loss : 8.588118553161621 valid loss : 22.667705535888672]\n",
      "[0334/1000 train loss : 8.594897747039795 valid loss : 22.723249435424805]\n",
      "[0335/1000 train loss : 8.47407054901123 valid loss : 22.765966415405273]\n",
      "[0336/1000 train loss : 8.550413370132446 valid loss : 22.534910202026367]\n",
      "[0337/1000 train loss : 8.541619300842285 valid loss : 22.634416580200195]\n",
      "[0338/1000 train loss : 8.50486969947815 valid loss : 22.604082107543945]\n",
      "[0339/1000 train loss : 8.343397378921509 valid loss : 22.530914306640625]\n",
      "[0340/1000 train loss : 8.320759296417236 valid loss : 22.51839828491211]\n",
      "[0341/1000 train loss : 8.492300987243652 valid loss : 22.535778045654297]\n",
      "[0342/1000 train loss : 8.374850273132324 valid loss : 22.4744873046875]\n",
      "[0343/1000 train loss : 8.086277484893799 valid loss : 22.420289993286133]\n",
      "[0344/1000 train loss : 8.280578136444092 valid loss : 22.573503494262695]\n",
      "[0345/1000 train loss : 8.290387868881226 valid loss : 22.318811416625977]\n",
      "[0346/1000 train loss : 8.40546202659607 valid loss : 22.51404571533203]\n",
      "[0347/1000 train loss : 8.271181583404541 valid loss : 22.346527099609375]\n",
      "[0348/1000 train loss : 8.467835187911987 valid loss : 22.323759078979492]\n",
      "[0349/1000 train loss : 8.257326126098633 valid loss : 22.410539627075195]\n",
      "[0350/1000 train loss : 8.316683769226074 valid loss : 22.475669860839844]\n",
      "[0351/1000 train loss : 8.338928699493408 valid loss : 22.14409828186035]\n",
      "[0352/1000 train loss : 8.1752450466156 valid loss : 22.248138427734375]\n",
      "[0353/1000 train loss : 8.187919616699219 valid loss : 22.41278648376465]\n",
      "[0354/1000 train loss : 8.190984725952148 valid loss : 22.353853225708008]\n",
      "[0355/1000 train loss : 8.103743553161621 valid loss : 22.420534133911133]\n",
      "[0356/1000 train loss : 8.193398714065552 valid loss : 22.119312286376953]\n",
      "[0357/1000 train loss : 8.06400728225708 valid loss : 22.110841751098633]\n",
      "[0358/1000 train loss : 8.010998249053955 valid loss : 22.208314895629883]\n",
      "[0359/1000 train loss : 8.092452764511108 valid loss : 22.4074649810791]\n",
      "[0360/1000 train loss : 8.081305027008057 valid loss : 22.138378143310547]\n",
      "[0361/1000 train loss : 8.097309350967407 valid loss : 22.08083152770996]\n",
      "[0362/1000 train loss : 8.043269157409668 valid loss : 22.04978370666504]\n",
      "[0363/1000 train loss : 8.032572507858276 valid loss : 22.24292755126953]\n",
      "[0364/1000 train loss : 8.001158952713013 valid loss : 22.052080154418945]\n",
      "[0365/1000 train loss : 7.994395732879639 valid loss : 22.019702911376953]\n",
      "[0366/1000 train loss : 7.982926607131958 valid loss : 21.970027923583984]\n",
      "[0367/1000 train loss : 7.980023622512817 valid loss : 21.96346664428711]\n",
      "[0368/1000 train loss : 7.448182821273804 valid loss : 22.128746032714844]\n",
      "[0369/1000 train loss : 7.889678478240967 valid loss : 22.046010971069336]\n",
      "[0370/1000 train loss : 8.06223750114441 valid loss : 22.419002532958984]\n",
      "[0371/1000 train loss : 7.841763973236084 valid loss : 22.11661148071289]\n",
      "[0372/1000 train loss : 7.7022154331207275 valid loss : 21.958663940429688]\n",
      "[0373/1000 train loss : 7.841790676116943 valid loss : 22.00358772277832]\n",
      "[0374/1000 train loss : 7.066647529602051 valid loss : 22.171751022338867]\n",
      "[0375/1000 train loss : 7.858199834823608 valid loss : 21.887554168701172]\n",
      "[0376/1000 train loss : 7.895131826400757 valid loss : 21.994077682495117]\n",
      "[0377/1000 train loss : 7.812684774398804 valid loss : 22.064659118652344]\n",
      "[0378/1000 train loss : 7.7633819580078125 valid loss : 21.948755264282227]\n",
      "[0379/1000 train loss : 7.766870975494385 valid loss : 22.01274871826172]\n",
      "[0380/1000 train loss : 7.726560831069946 valid loss : 22.02791976928711]\n",
      "[0381/1000 train loss : 7.643116474151611 valid loss : 21.801477432250977]\n",
      "[0382/1000 train loss : 7.6706178188323975 valid loss : 21.883813858032227]\n",
      "[0383/1000 train loss : 7.7505152225494385 valid loss : 22.048988342285156]\n",
      "[0384/1000 train loss : 7.658486604690552 valid loss : 21.808311462402344]\n",
      "[0385/1000 train loss : 7.574094772338867 valid loss : 21.86894989013672]\n",
      "[0386/1000 train loss : 6.970736742019653 valid loss : 22.168991088867188]\n",
      "[0387/1000 train loss : 7.6401894092559814 valid loss : 21.937768936157227]\n",
      "[0388/1000 train loss : 7.6580657958984375 valid loss : 21.76030731201172]\n",
      "[0389/1000 train loss : 7.636348724365234 valid loss : 21.768598556518555]\n",
      "[0390/1000 train loss : 7.614195346832275 valid loss : 21.899677276611328]\n",
      "[0391/1000 train loss : 7.5496392250061035 valid loss : 21.636072158813477]\n",
      "[0392/1000 train loss : 7.597841501235962 valid loss : 21.689271926879883]\n",
      "[0393/1000 train loss : 7.644023418426514 valid loss : 21.867055892944336]\n",
      "[0394/1000 train loss : 7.660323619842529 valid loss : 21.809629440307617]\n",
      "[0395/1000 train loss : 7.544670820236206 valid loss : 21.565122604370117]\n",
      "[0396/1000 train loss : 7.575699090957642 valid loss : 21.791332244873047]\n",
      "[0397/1000 train loss : 7.49536657333374 valid loss : 21.670108795166016]\n",
      "[0398/1000 train loss : 7.501500606536865 valid loss : 21.577110290527344]\n",
      "[0399/1000 train loss : 7.496597766876221 valid loss : 21.554229736328125]\n",
      "[0400/1000 train loss : 7.429652452468872 valid loss : 21.61156463623047]\n",
      "[0401/1000 train loss : 7.391244411468506 valid loss : 21.517745971679688]\n",
      "[0402/1000 train loss : 7.433708906173706 valid loss : 21.597946166992188]\n",
      "[0403/1000 train loss : 7.443573236465454 valid loss : 21.58498191833496]\n",
      "[0404/1000 train loss : 7.521185398101807 valid loss : 21.53580093383789]\n",
      "[0405/1000 train loss : 7.221046209335327 valid loss : 21.470563888549805]\n",
      "[0406/1000 train loss : 7.3334925174713135 valid loss : 21.480010986328125]\n",
      "[0407/1000 train loss : 7.405004978179932 valid loss : 21.357044219970703]\n",
      "[0408/1000 train loss : 7.327883958816528 valid loss : 21.539365768432617]\n",
      "[0409/1000 train loss : 7.365259408950806 valid loss : 21.467790603637695]\n",
      "[0410/1000 train loss : 7.330324172973633 valid loss : 21.374486923217773]\n",
      "[0411/1000 train loss : 7.381587982177734 valid loss : 21.41531753540039]\n",
      "[0412/1000 train loss : 7.281030178070068 valid loss : 21.722074508666992]\n",
      "[0413/1000 train loss : 7.369476318359375 valid loss : 21.52467918395996]\n",
      "[0414/1000 train loss : 7.266275644302368 valid loss : 21.382457733154297]\n",
      "[0415/1000 train loss : 7.1987245082855225 valid loss : 21.46722984313965]\n",
      "[0416/1000 train loss : 7.291418552398682 valid loss : 21.305269241333008]\n",
      "[0417/1000 train loss : 7.229105234146118 valid loss : 21.42107582092285]\n",
      "[0418/1000 train loss : 7.235462665557861 valid loss : 21.3061466217041]\n",
      "[0419/1000 train loss : 7.180618762969971 valid loss : 21.39943504333496]\n",
      "[0420/1000 train loss : 7.153589248657227 valid loss : 21.149621963500977]\n",
      "[0421/1000 train loss : 7.251659631729126 valid loss : 21.166343688964844]\n",
      "[0422/1000 train loss : 7.174285411834717 valid loss : 21.122474670410156]\n",
      "[0423/1000 train loss : 6.565112352371216 valid loss : 21.429601669311523]\n",
      "[0424/1000 train loss : 7.168993234634399 valid loss : 21.21958351135254]\n",
      "[0425/1000 train loss : 7.130527973175049 valid loss : 21.26116371154785]\n",
      "[0426/1000 train loss : 7.0454466342926025 valid loss : 21.299182891845703]\n",
      "[0427/1000 train loss : 7.113013505935669 valid loss : 21.339113235473633]\n",
      "[0428/1000 train loss : 7.01688814163208 valid loss : 21.292938232421875]\n",
      "[0429/1000 train loss : 7.06883430480957 valid loss : 21.194168090820312]\n",
      "[0430/1000 train loss : 7.0041184425354 valid loss : 21.27496910095215]\n",
      "[0431/1000 train loss : 7.104332208633423 valid loss : 21.02197265625]\n",
      "[0432/1000 train loss : 7.0004894733428955 valid loss : 21.30085563659668]\n",
      "[0433/1000 train loss : 7.105679512023926 valid loss : 21.30190658569336]\n",
      "[0434/1000 train loss : 7.0734639167785645 valid loss : 21.21048355102539]\n",
      "[0435/1000 train loss : 6.962284564971924 valid loss : 21.167282104492188]\n",
      "[0436/1000 train loss : 6.958047389984131 valid loss : 21.16291046142578]\n",
      "[0437/1000 train loss : 6.967242479324341 valid loss : 21.38589859008789]\n",
      "[0438/1000 train loss : 6.972884654998779 valid loss : 21.148956298828125]\n",
      "[0439/1000 train loss : 6.879056453704834 valid loss : 21.079917907714844]\n",
      "[0440/1000 train loss : 6.9027464389801025 valid loss : 21.188413619995117]\n",
      "[0441/1000 train loss : 7.018326044082642 valid loss : 21.085956573486328]\n",
      "[0442/1000 train loss : 6.970869779586792 valid loss : 21.362001419067383]\n",
      "[0443/1000 train loss : 7.1105241775512695 valid loss : 21.29202651977539]\n",
      "[0444/1000 train loss : 7.045555830001831 valid loss : 20.853221893310547]\n",
      "[0445/1000 train loss : 6.947422504425049 valid loss : 21.085460662841797]\n",
      "[0446/1000 train loss : 7.00176477432251 valid loss : 20.810678482055664]\n",
      "[0447/1000 train loss : 6.999637603759766 valid loss : 21.21916389465332]\n",
      "[0448/1000 train loss : 6.838510274887085 valid loss : 21.066696166992188]\n",
      "[0449/1000 train loss : 6.81112813949585 valid loss : 20.976001739501953]\n",
      "[0450/1000 train loss : 6.845451831817627 valid loss : 20.972665786743164]\n",
      "[0451/1000 train loss : 6.71439528465271 valid loss : 20.95220184326172]\n",
      "[0452/1000 train loss : 6.780311584472656 valid loss : 20.921005249023438]\n",
      "[0453/1000 train loss : 6.761177062988281 valid loss : 20.87724494934082]\n",
      "[0454/1000 train loss : 6.824386358261108 valid loss : 20.889366149902344]\n",
      "[0455/1000 train loss : 6.851128101348877 valid loss : 20.897884368896484]\n",
      "[0456/1000 train loss : 6.641489267349243 valid loss : 20.691118240356445]\n",
      "[0457/1000 train loss : 6.833220481872559 valid loss : 20.88010025024414]\n",
      "[0458/1000 train loss : 6.70187520980835 valid loss : 20.988754272460938]\n",
      "[0459/1000 train loss : 6.741943120956421 valid loss : 20.864717483520508]\n",
      "[0460/1000 train loss : 6.700873613357544 valid loss : 21.00732421875]\n",
      "[0461/1000 train loss : 6.683624982833862 valid loss : 20.656238555908203]\n",
      "[0462/1000 train loss : 6.130939722061157 valid loss : 20.53820037841797]\n",
      "[0463/1000 train loss : 6.7566399574279785 valid loss : 20.61715316772461]\n",
      "[0464/1000 train loss : 6.657099008560181 valid loss : 20.752304077148438]\n",
      "[0465/1000 train loss : 6.662631988525391 valid loss : 20.91674041748047]\n",
      "[0466/1000 train loss : 6.790407180786133 valid loss : 20.688983917236328]\n",
      "[0467/1000 train loss : 6.763901710510254 valid loss : 20.789199829101562]\n",
      "[0468/1000 train loss : 6.65064001083374 valid loss : 20.777631759643555]\n",
      "[0469/1000 train loss : 6.58715295791626 valid loss : 20.828838348388672]\n",
      "[0470/1000 train loss : 6.6034393310546875 valid loss : 20.785539627075195]\n",
      "[0471/1000 train loss : 6.574824333190918 valid loss : 20.699569702148438]\n",
      "[0472/1000 train loss : 6.597140550613403 valid loss : 20.715435028076172]\n",
      "[0473/1000 train loss : 6.5561301708221436 valid loss : 21.015443801879883]\n",
      "[0474/1000 train loss : 6.685641527175903 valid loss : 20.959564208984375]\n",
      "[0475/1000 train loss : 6.511486053466797 valid loss : 20.821640014648438]\n",
      "[0476/1000 train loss : 6.54900336265564 valid loss : 20.639663696289062]\n",
      "[0477/1000 train loss : 6.530578374862671 valid loss : 20.70939064025879]\n",
      "[0478/1000 train loss : 6.551674127578735 valid loss : 20.64093589782715]\n",
      "[0479/1000 train loss : 6.339283227920532 valid loss : 20.58383560180664]\n",
      "[0480/1000 train loss : 6.502669811248779 valid loss : 20.851654052734375]\n",
      "[0481/1000 train loss : 6.517532587051392 valid loss : 20.847768783569336]\n",
      "[0482/1000 train loss : 6.461864709854126 valid loss : 20.62126350402832]\n",
      "[0483/1000 train loss : 6.435736656188965 valid loss : 20.837661743164062]\n",
      "[0484/1000 train loss : 6.401207447052002 valid loss : 20.737483978271484]\n",
      "[0485/1000 train loss : 6.5147788524627686 valid loss : 20.553375244140625]\n",
      "[0486/1000 train loss : 6.464946985244751 valid loss : 20.49785041809082]\n",
      "[0487/1000 train loss : 6.653039932250977 valid loss : 20.85637855529785]\n",
      "[0488/1000 train loss : 6.640819072723389 valid loss : 20.46695899963379]\n",
      "[0489/1000 train loss : 6.475499868392944 valid loss : 20.4860897064209]\n",
      "[0490/1000 train loss : 6.441460847854614 valid loss : 20.507287979125977]\n",
      "[0491/1000 train loss : 6.471269369125366 valid loss : 20.56533432006836]\n",
      "[0492/1000 train loss : 6.488906145095825 valid loss : 20.716903686523438]\n",
      "[0493/1000 train loss : 6.395338535308838 valid loss : 20.59238052368164]\n",
      "[0494/1000 train loss : 6.422360181808472 valid loss : 20.567821502685547]\n",
      "[0495/1000 train loss : 6.40789008140564 valid loss : 20.614952087402344]\n",
      "[0496/1000 train loss : 6.347218751907349 valid loss : 20.57879066467285]\n",
      "[0497/1000 train loss : 6.361630916595459 valid loss : 20.4851016998291]\n",
      "[0498/1000 train loss : 6.411992788314819 valid loss : 20.564716339111328]\n",
      "[0499/1000 train loss : 6.312932729721069 valid loss : 20.4539737701416]\n",
      "[0500/1000 train loss : 6.314634323120117 valid loss : 20.42102813720703]\n",
      "[0501/1000 train loss : 6.333991050720215 valid loss : 20.657806396484375]\n",
      "[0502/1000 train loss : 6.369396209716797 valid loss : 20.63965606689453]\n",
      "[0503/1000 train loss : 6.422784090042114 valid loss : 20.67365074157715]\n",
      "[0504/1000 train loss : 6.2834954261779785 valid loss : 20.486610412597656]\n",
      "[0505/1000 train loss : 6.2986085414886475 valid loss : 20.604772567749023]\n",
      "[0506/1000 train loss : 6.287949562072754 valid loss : 20.36528205871582]\n",
      "[0507/1000 train loss : 6.2839133739471436 valid loss : 20.620397567749023]\n",
      "[0508/1000 train loss : 6.1419641971588135 valid loss : 20.681604385375977]\n",
      "[0509/1000 train loss : 6.397353410720825 valid loss : 20.86602210998535]\n",
      "[0510/1000 train loss : 6.1859235763549805 valid loss : 20.564130783081055]\n",
      "[0511/1000 train loss : 6.204951524734497 valid loss : 20.596099853515625]\n",
      "[0512/1000 train loss : 6.273174047470093 valid loss : 20.52798080444336]\n",
      "[0513/1000 train loss : 6.209250450134277 valid loss : 20.504379272460938]\n",
      "[0514/1000 train loss : 6.258521318435669 valid loss : 20.59227752685547]\n",
      "[0515/1000 train loss : 6.2015769481658936 valid loss : 20.39834213256836]\n",
      "[0516/1000 train loss : 6.089122533798218 valid loss : 20.41245460510254]\n",
      "[0517/1000 train loss : 6.190675973892212 valid loss : 20.33134651184082]\n",
      "[0518/1000 train loss : 6.096617937088013 valid loss : 20.500307083129883]\n",
      "[0519/1000 train loss : 6.0109405517578125 valid loss : 20.445249557495117]\n",
      "[0520/1000 train loss : 6.139226198196411 valid loss : 20.51068878173828]\n",
      "[0521/1000 train loss : 6.115819692611694 valid loss : 20.39175796508789]\n",
      "[0522/1000 train loss : 6.163549423217773 valid loss : 20.351648330688477]\n",
      "[0523/1000 train loss : 6.1747331619262695 valid loss : 20.401073455810547]\n",
      "[0524/1000 train loss : 6.138028383255005 valid loss : 20.428876876831055]\n",
      "[0525/1000 train loss : 6.141790866851807 valid loss : 20.222328186035156]\n",
      "[0526/1000 train loss : 6.14096999168396 valid loss : 20.39620590209961]\n",
      "[0527/1000 train loss : 6.149372816085815 valid loss : 20.329832077026367]\n",
      "[0528/1000 train loss : 6.11177396774292 valid loss : 20.081640243530273]\n",
      "[0529/1000 train loss : 6.129877090454102 valid loss : 20.23705291748047]\n",
      "[0530/1000 train loss : 6.109528303146362 valid loss : 20.28346824645996]\n",
      "[0531/1000 train loss : 6.0365965366363525 valid loss : 20.245616912841797]\n",
      "[0532/1000 train loss : 6.055530309677124 valid loss : 20.457000732421875]\n",
      "[0533/1000 train loss : 6.032711744308472 valid loss : 20.465087890625]\n",
      "[0534/1000 train loss : 6.1328630447387695 valid loss : 20.136287689208984]\n",
      "[0535/1000 train loss : 5.637037754058838 valid loss : 20.40888786315918]\n",
      "[0536/1000 train loss : 6.015397071838379 valid loss : 20.296451568603516]\n",
      "[0537/1000 train loss : 5.917188405990601 valid loss : 20.075801849365234]\n",
      "[0538/1000 train loss : 5.932983160018921 valid loss : 20.22195053100586]\n",
      "[0539/1000 train loss : 6.009385347366333 valid loss : 20.354631423950195]\n",
      "[0540/1000 train loss : 6.0919623374938965 valid loss : 20.357118606567383]\n",
      "[0541/1000 train loss : 6.058697700500488 valid loss : 20.268537521362305]\n",
      "[0542/1000 train loss : 6.015843868255615 valid loss : 20.27492904663086]\n",
      "[0543/1000 train loss : 6.004663705825806 valid loss : 20.3178653717041]\n",
      "[0544/1000 train loss : 5.956935405731201 valid loss : 20.420804977416992]\n",
      "[0545/1000 train loss : 5.812254905700684 valid loss : 20.309804916381836]\n",
      "[0546/1000 train loss : 5.970344305038452 valid loss : 20.33131980895996]\n",
      "[0547/1000 train loss : 5.9353132247924805 valid loss : 20.271373748779297]\n",
      "[0548/1000 train loss : 5.921248197555542 valid loss : 20.2568416595459]\n",
      "[0549/1000 train loss : 5.888903379440308 valid loss : 20.286623001098633]\n",
      "[0550/1000 train loss : 5.969419240951538 valid loss : 20.30320167541504]\n",
      "[0551/1000 train loss : 5.963771104812622 valid loss : 20.172136306762695]\n",
      "[0552/1000 train loss : 5.89130711555481 valid loss : 19.975584030151367]\n",
      "[0553/1000 train loss : 5.928736448287964 valid loss : 20.15892791748047]\n",
      "[0554/1000 train loss : 5.869222402572632 valid loss : 20.251201629638672]\n",
      "[0555/1000 train loss : 5.874483585357666 valid loss : 20.349227905273438]\n",
      "[0556/1000 train loss : 5.8455705642700195 valid loss : 20.124095916748047]\n",
      "[0557/1000 train loss : 5.852228879928589 valid loss : 20.038408279418945]\n",
      "[0558/1000 train loss : 5.750648021697998 valid loss : 20.06395149230957]\n",
      "[0559/1000 train loss : 5.8460845947265625 valid loss : 20.143470764160156]\n",
      "[0560/1000 train loss : 5.763771176338196 valid loss : 20.11787986755371]\n",
      "[0561/1000 train loss : 5.886006832122803 valid loss : 19.94170570373535]\n",
      "[0562/1000 train loss : 5.894800186157227 valid loss : 19.988414764404297]\n",
      "[0563/1000 train loss : 5.889728784561157 valid loss : 20.161800384521484]\n",
      "[0564/1000 train loss : 5.658836364746094 valid loss : 20.39191436767578]\n",
      "[0565/1000 train loss : 5.9265382289886475 valid loss : 20.12613868713379]\n",
      "[0566/1000 train loss : 5.925160884857178 valid loss : 20.17399024963379]\n",
      "[0567/1000 train loss : 5.824533700942993 valid loss : 20.019119262695312]\n",
      "[0568/1000 train loss : 5.859300136566162 valid loss : 20.0425968170166]\n",
      "[0569/1000 train loss : 5.768059015274048 valid loss : 19.991413116455078]\n",
      "[0570/1000 train loss : 5.663179874420166 valid loss : 20.171186447143555]\n",
      "[0571/1000 train loss : 5.748734474182129 valid loss : 20.15207862854004]\n",
      "[0572/1000 train loss : 5.774499416351318 valid loss : 19.976505279541016]\n",
      "[0573/1000 train loss : 5.771808624267578 valid loss : 19.84126853942871]\n",
      "[0574/1000 train loss : 5.79655385017395 valid loss : 20.337467193603516]\n",
      "[0575/1000 train loss : 5.7564918994903564 valid loss : 20.14769744873047]\n",
      "[0576/1000 train loss : 5.6350929737091064 valid loss : 19.88875961303711]\n",
      "[0577/1000 train loss : 5.653726816177368 valid loss : 20.07137107849121]\n",
      "[0578/1000 train loss : 5.7017905712127686 valid loss : 20.13471794128418]\n",
      "[0579/1000 train loss : 5.728281259536743 valid loss : 20.29817008972168]\n",
      "[0580/1000 train loss : 5.681643009185791 valid loss : 20.100624084472656]\n",
      "[0581/1000 train loss : 5.674903631210327 valid loss : 19.92555046081543]\n",
      "[0582/1000 train loss : 5.65927267074585 valid loss : 20.019678115844727]\n",
      "[0583/1000 train loss : 5.689697504043579 valid loss : 19.96565818786621]\n",
      "[0584/1000 train loss : 5.706293821334839 valid loss : 20.065673828125]\n",
      "[0585/1000 train loss : 5.712441682815552 valid loss : 19.943553924560547]\n",
      "[0586/1000 train loss : 5.751990556716919 valid loss : 20.286378860473633]\n",
      "[0587/1000 train loss : 5.668238878250122 valid loss : 20.097753524780273]\n",
      "[0588/1000 train loss : 5.6728129386901855 valid loss : 20.075733184814453]\n",
      "[0589/1000 train loss : 5.700611352920532 valid loss : 19.985742568969727]\n",
      "[0590/1000 train loss : 5.6359124183654785 valid loss : 19.964508056640625]\n",
      "[0591/1000 train loss : 5.251776933670044 valid loss : 20.169160842895508]\n",
      "[0592/1000 train loss : 5.639864444732666 valid loss : 19.86399269104004]\n",
      "[0593/1000 train loss : 5.620826721191406 valid loss : 20.310190200805664]\n",
      "[0594/1000 train loss : 5.614266633987427 valid loss : 19.979690551757812]\n",
      "[0595/1000 train loss : 5.608989953994751 valid loss : 19.93451499938965]\n",
      "[0596/1000 train loss : 5.615575075149536 valid loss : 19.85662269592285]\n",
      "[0597/1000 train loss : 5.60658860206604 valid loss : 20.096240997314453]\n",
      "[0598/1000 train loss : 5.618126392364502 valid loss : 19.863040924072266]\n",
      "[0599/1000 train loss : 5.462025165557861 valid loss : 19.747159957885742]\n",
      "[0600/1000 train loss : 5.541661500930786 valid loss : 19.958024978637695]\n",
      "[0601/1000 train loss : 5.554280042648315 valid loss : 19.698217391967773]\n",
      "[0602/1000 train loss : 5.646044731140137 valid loss : 19.818225860595703]\n",
      "[0603/1000 train loss : 5.580470561981201 valid loss : 19.906238555908203]\n",
      "[0604/1000 train loss : 5.540888071060181 valid loss : 19.846818923950195]\n",
      "[0605/1000 train loss : 5.56615424156189 valid loss : 19.797712326049805]\n",
      "[0606/1000 train loss : 5.511132001876831 valid loss : 19.80197525024414]\n",
      "[0607/1000 train loss : 5.491364002227783 valid loss : 19.829578399658203]\n",
      "[0608/1000 train loss : 5.5546934604644775 valid loss : 19.924636840820312]\n",
      "[0609/1000 train loss : 5.474855184555054 valid loss : 19.84893035888672]\n",
      "[0610/1000 train loss : 5.535407543182373 valid loss : 20.02399253845215]\n",
      "[0611/1000 train loss : 5.525309324264526 valid loss : 19.805248260498047]\n",
      "[0612/1000 train loss : 5.443006753921509 valid loss : 20.03607940673828]\n",
      "[0613/1000 train loss : 5.479689359664917 valid loss : 19.8780460357666]\n",
      "[0614/1000 train loss : 5.561810493469238 valid loss : 19.995651245117188]\n",
      "[0615/1000 train loss : 5.484473705291748 valid loss : 19.770442962646484]\n",
      "[0616/1000 train loss : 5.522971153259277 valid loss : 19.7733154296875]\n",
      "[0617/1000 train loss : 5.555444002151489 valid loss : 19.70952606201172]\n",
      "[0618/1000 train loss : 5.483011484146118 valid loss : 19.870676040649414]\n",
      "[0619/1000 train loss : 5.485489130020142 valid loss : 19.928279876708984]\n",
      "[0620/1000 train loss : 5.466410398483276 valid loss : 19.98703384399414]\n",
      "[0621/1000 train loss : 5.460864782333374 valid loss : 19.959259033203125]\n",
      "[0622/1000 train loss : 5.516683578491211 valid loss : 19.87172508239746]\n",
      "[0623/1000 train loss : 5.3605194091796875 valid loss : 19.840892791748047]\n",
      "[0624/1000 train loss : 5.424185514450073 valid loss : 19.61838722229004]\n",
      "[0625/1000 train loss : 5.441396951675415 valid loss : 19.56613540649414]\n",
      "[0626/1000 train loss : 5.552060127258301 valid loss : 19.532421112060547]\n",
      "[0627/1000 train loss : 5.474693536758423 valid loss : 19.56577491760254]\n",
      "[0628/1000 train loss : 5.412357807159424 valid loss : 19.68669319152832]\n",
      "[0629/1000 train loss : 5.381360769271851 valid loss : 19.777416229248047]\n",
      "[0630/1000 train loss : 5.393932819366455 valid loss : 19.974273681640625]\n",
      "[0631/1000 train loss : 5.262505531311035 valid loss : 19.830541610717773]\n",
      "[0632/1000 train loss : 5.398841857910156 valid loss : 19.671716690063477]\n",
      "[0633/1000 train loss : 5.4018778800964355 valid loss : 19.93706512451172]\n",
      "[0634/1000 train loss : 5.370008230209351 valid loss : 19.624298095703125]\n",
      "[0635/1000 train loss : 5.386700391769409 valid loss : 19.6218318939209]\n",
      "[0636/1000 train loss : 5.574090242385864 valid loss : 20.016735076904297]\n",
      "[0637/1000 train loss : 5.404668092727661 valid loss : 19.6424617767334]\n",
      "[0638/1000 train loss : 5.318817853927612 valid loss : 19.707185745239258]\n",
      "[0639/1000 train loss : 5.350921392440796 valid loss : 19.596664428710938]\n",
      "[0640/1000 train loss : 5.333025693893433 valid loss : 19.797378540039062]\n",
      "[0641/1000 train loss : 5.35509729385376 valid loss : 19.520326614379883]\n",
      "[0642/1000 train loss : 5.26007866859436 valid loss : 19.72793960571289]\n",
      "[0643/1000 train loss : 5.365547180175781 valid loss : 19.58513069152832]\n",
      "[0644/1000 train loss : 5.297241926193237 valid loss : 19.724485397338867]\n",
      "[0645/1000 train loss : 5.354680061340332 valid loss : 19.840137481689453]\n",
      "[0646/1000 train loss : 5.277270317077637 valid loss : 19.780746459960938]\n",
      "[0647/1000 train loss : 5.30615758895874 valid loss : 19.982696533203125]\n",
      "[0648/1000 train loss : 5.270352125167847 valid loss : 19.732990264892578]\n",
      "[0649/1000 train loss : 5.263896465301514 valid loss : 19.633832931518555]\n",
      "[0650/1000 train loss : 5.290709018707275 valid loss : 19.686431884765625]\n",
      "[0651/1000 train loss : 5.3410656452178955 valid loss : 19.616968154907227]\n",
      "[0652/1000 train loss : 5.30511999130249 valid loss : 19.82306671142578]\n",
      "[0653/1000 train loss : 5.301454067230225 valid loss : 19.84128761291504]\n",
      "[0654/1000 train loss : 5.23979640007019 valid loss : 19.767574310302734]\n",
      "[0655/1000 train loss : 5.380869388580322 valid loss : 19.786970138549805]\n",
      "[0656/1000 train loss : 5.324810266494751 valid loss : 19.55618667602539]\n",
      "[0657/1000 train loss : 5.257755756378174 valid loss : 19.683584213256836]\n",
      "[0658/1000 train loss : 5.196042060852051 valid loss : 19.776721954345703]\n",
      "[0659/1000 train loss : 5.239076852798462 valid loss : 19.59159278869629]\n",
      "[0660/1000 train loss : 5.212619781494141 valid loss : 19.837926864624023]\n",
      "[0661/1000 train loss : 5.199160099029541 valid loss : 19.503509521484375]\n",
      "[0662/1000 train loss : 4.906901121139526 valid loss : 19.87706756591797]\n",
      "[0663/1000 train loss : 5.20219612121582 valid loss : 19.533143997192383]\n",
      "[0664/1000 train loss : 4.932858228683472 valid loss : 19.532867431640625]\n",
      "[0665/1000 train loss : 5.190744400024414 valid loss : 19.496816635131836]\n",
      "[0666/1000 train loss : 5.241211891174316 valid loss : 19.854745864868164]\n",
      "[0667/1000 train loss : 5.167152166366577 valid loss : 19.652507781982422]\n",
      "[0668/1000 train loss : 5.187598705291748 valid loss : 19.64357566833496]\n",
      "[0669/1000 train loss : 5.18742823600769 valid loss : 19.71077537536621]\n",
      "[0670/1000 train loss : 5.240559101104736 valid loss : 19.94154930114746]\n",
      "[0671/1000 train loss : 5.096912860870361 valid loss : 19.56986427307129]\n",
      "[0672/1000 train loss : 5.16732931137085 valid loss : 19.893789291381836]\n",
      "[0673/1000 train loss : 5.134773015975952 valid loss : 19.897241592407227]\n",
      "[0674/1000 train loss : 5.18716025352478 valid loss : 19.724817276000977]\n",
      "[0675/1000 train loss : 5.2781853675842285 valid loss : 19.84554672241211]\n",
      "[0676/1000 train loss : 5.157893896102905 valid loss : 19.628652572631836]\n",
      "[0677/1000 train loss : 5.1517438888549805 valid loss : 19.548526763916016]\n",
      "[0678/1000 train loss : 5.099853277206421 valid loss : 19.69391441345215]\n",
      "[0679/1000 train loss : 5.126027345657349 valid loss : 19.59065818786621]\n",
      "[0680/1000 train loss : 5.130199670791626 valid loss : 19.51878547668457]\n",
      "[0681/1000 train loss : 5.076564788818359 valid loss : 19.77431869506836]\n",
      "[0682/1000 train loss : 5.12993597984314 valid loss : 19.696548461914062]\n",
      "[0683/1000 train loss : 5.172489643096924 valid loss : 19.515392303466797]\n",
      "[0684/1000 train loss : 5.141944646835327 valid loss : 19.487672805786133]\n",
      "[0685/1000 train loss : 5.155512809753418 valid loss : 19.72702407836914]\n",
      "[0686/1000 train loss : 5.235848903656006 valid loss : 19.757688522338867]\n",
      "[0687/1000 train loss : 5.043366432189941 valid loss : 19.998130798339844]\n",
      "[0688/1000 train loss : 5.059839963912964 valid loss : 19.6715145111084]\n",
      "[0689/1000 train loss : 5.086112976074219 valid loss : 19.628314971923828]\n",
      "[0690/1000 train loss : 5.0595269203186035 valid loss : 19.506275177001953]\n",
      "[0691/1000 train loss : 5.0787880420684814 valid loss : 19.629011154174805]\n",
      "[0692/1000 train loss : 5.051282644271851 valid loss : 19.415210723876953]\n",
      "[0693/1000 train loss : 5.084346294403076 valid loss : 19.58622169494629]\n",
      "[0694/1000 train loss : 5.070119142532349 valid loss : 19.4987850189209]\n",
      "[0695/1000 train loss : 5.034001350402832 valid loss : 19.638681411743164]\n",
      "[0696/1000 train loss : 5.010323762893677 valid loss : 19.65591812133789]\n",
      "[0697/1000 train loss : 5.0964674949646 valid loss : 19.776063919067383]\n",
      "[0698/1000 train loss : 5.036836862564087 valid loss : 19.47171974182129]\n",
      "[0699/1000 train loss : 4.979551315307617 valid loss : 19.510417938232422]\n",
      "[0700/1000 train loss : 5.039829730987549 valid loss : 19.627227783203125]\n",
      "[0701/1000 train loss : 5.010634899139404 valid loss : 19.685211181640625]\n",
      "[0702/1000 train loss : 5.003206968307495 valid loss : 19.61954116821289]\n",
      "[0703/1000 train loss : 5.149862289428711 valid loss : 19.44439697265625]\n",
      "[0704/1000 train loss : 5.068628549575806 valid loss : 19.65161895751953]\n",
      "[0705/1000 train loss : 5.037206411361694 valid loss : 19.46820640563965]\n",
      "[0706/1000 train loss : 5.034560441970825 valid loss : 19.675037384033203]\n",
      "[0707/1000 train loss : 4.818280458450317 valid loss : 19.25838851928711]\n",
      "[0708/1000 train loss : 5.095461368560791 valid loss : 19.451704025268555]\n",
      "[0709/1000 train loss : 4.954296350479126 valid loss : 19.439966201782227]\n",
      "[0710/1000 train loss : 5.025498628616333 valid loss : 19.812328338623047]\n",
      "[0711/1000 train loss : 5.023195028305054 valid loss : 19.78420066833496]\n",
      "[0712/1000 train loss : 5.001613140106201 valid loss : 19.513973236083984]\n",
      "[0713/1000 train loss : 4.9860944747924805 valid loss : 19.620590209960938]\n",
      "[0714/1000 train loss : 4.982643127441406 valid loss : 19.648351669311523]\n",
      "[0715/1000 train loss : 4.964745283126831 valid loss : 19.577369689941406]\n",
      "[0716/1000 train loss : 4.964009761810303 valid loss : 19.670499801635742]\n",
      "[0717/1000 train loss : 5.040934801101685 valid loss : 19.390275955200195]\n",
      "[0718/1000 train loss : 4.971746921539307 valid loss : 19.605127334594727]\n",
      "[0719/1000 train loss : 5.0150065422058105 valid loss : 19.38998794555664]\n",
      "[0720/1000 train loss : 4.9196484088897705 valid loss : 19.3460636138916]\n",
      "[0721/1000 train loss : 4.779179334640503 valid loss : 19.435630798339844]\n",
      "[0722/1000 train loss : 4.942255735397339 valid loss : 19.60178565979004]\n",
      "[0723/1000 train loss : 4.913870096206665 valid loss : 19.4771671295166]\n",
      "[0724/1000 train loss : 4.991936683654785 valid loss : 19.853057861328125]\n",
      "[0725/1000 train loss : 4.996398448944092 valid loss : 19.845386505126953]\n",
      "[0726/1000 train loss : 4.953956127166748 valid loss : 19.396520614624023]\n",
      "[0727/1000 train loss : 4.893486976623535 valid loss : 19.50011444091797]\n",
      "[0728/1000 train loss : 4.895205497741699 valid loss : 19.54555320739746]\n",
      "[0729/1000 train loss : 4.8133225440979 valid loss : 19.501901626586914]\n",
      "[0730/1000 train loss : 4.893256664276123 valid loss : 19.571531295776367]\n",
      "[0731/1000 train loss : 4.895559787750244 valid loss : 19.318859100341797]\n",
      "[0732/1000 train loss : 4.849456071853638 valid loss : 19.512557983398438]\n",
      "[0733/1000 train loss : 4.841184377670288 valid loss : 19.464374542236328]\n",
      "[0734/1000 train loss : 4.994339227676392 valid loss : 19.62418556213379]\n",
      "[0735/1000 train loss : 4.887990951538086 valid loss : 19.576244354248047]\n",
      "[0736/1000 train loss : 4.87068772315979 valid loss : 19.345508575439453]\n",
      "[0737/1000 train loss : 4.958891272544861 valid loss : 19.355798721313477]\n",
      "[0738/1000 train loss : 4.779954195022583 valid loss : 19.528345108032227]\n",
      "[0739/1000 train loss : 4.818752765655518 valid loss : 19.402456283569336]\n",
      "[0740/1000 train loss : 4.868195056915283 valid loss : 19.73313331604004]\n",
      "[0741/1000 train loss : 4.839568614959717 valid loss : 19.563764572143555]\n",
      "[0742/1000 train loss : 4.863418221473694 valid loss : 19.556331634521484]\n",
      "[0743/1000 train loss : 4.800683259963989 valid loss : 19.296951293945312]\n",
      "[0744/1000 train loss : 4.79358434677124 valid loss : 19.536008834838867]\n",
      "[0745/1000 train loss : 4.834081649780273 valid loss : 19.612655639648438]\n",
      "[0746/1000 train loss : 4.764469027519226 valid loss : 19.75461196899414]\n",
      "[0747/1000 train loss : 4.733628034591675 valid loss : 19.369054794311523]\n",
      "[0748/1000 train loss : 4.805822849273682 valid loss : 19.420154571533203]\n",
      "[0749/1000 train loss : 4.799422264099121 valid loss : 19.5988826751709]\n",
      "[0750/1000 train loss : 4.723724126815796 valid loss : 19.459909439086914]\n",
      "[0751/1000 train loss : 4.781381368637085 valid loss : 19.473405838012695]\n",
      "[0752/1000 train loss : 4.75937557220459 valid loss : 19.377634048461914]\n",
      "[0753/1000 train loss : 4.87256133556366 valid loss : 19.58312225341797]\n",
      "[0754/1000 train loss : 4.794041395187378 valid loss : 19.494991302490234]\n",
      "[0755/1000 train loss : 4.789856910705566 valid loss : 19.79047203063965]\n",
      "[0756/1000 train loss : 4.828882694244385 valid loss : 19.67295265197754]\n",
      "[0757/1000 train loss : 4.714652419090271 valid loss : 19.530641555786133]\n",
      "[0758/1000 train loss : 4.766808748245239 valid loss : 19.641252517700195]\n",
      "[0759/1000 train loss : 4.762519836425781 valid loss : 19.219892501831055]\n",
      "[0760/1000 train loss : 4.759738922119141 valid loss : 19.416217803955078]\n",
      "[0761/1000 train loss : 4.749117851257324 valid loss : 19.70833969116211]\n",
      "[0762/1000 train loss : 4.692500829696655 valid loss : 19.161483764648438]\n",
      "[0763/1000 train loss : 4.727335691452026 valid loss : 19.1580810546875]\n",
      "[0764/1000 train loss : 4.8236565589904785 valid loss : 19.61896514892578]\n",
      "[0765/1000 train loss : 4.662442207336426 valid loss : 19.411069869995117]\n",
      "[0766/1000 train loss : 4.775151014328003 valid loss : 19.509140014648438]\n",
      "[0767/1000 train loss : 4.709416151046753 valid loss : 19.868711471557617]\n",
      "[0768/1000 train loss : 4.693328142166138 valid loss : 19.53752899169922]\n",
      "[0769/1000 train loss : 4.711211204528809 valid loss : 19.576995849609375]\n",
      "[0770/1000 train loss : 4.718116283416748 valid loss : 19.393447875976562]\n",
      "[0771/1000 train loss : 4.569896340370178 valid loss : 19.310577392578125]\n",
      "[0772/1000 train loss : 4.70232367515564 valid loss : 19.806289672851562]\n",
      "[0773/1000 train loss : 4.812880992889404 valid loss : 19.757097244262695]\n",
      "[0774/1000 train loss : 4.784623384475708 valid loss : 19.53898811340332]\n",
      "[0775/1000 train loss : 4.631549119949341 valid loss : 19.309995651245117]\n",
      "[0776/1000 train loss : 4.650378465652466 valid loss : 19.338151931762695]\n",
      "[0777/1000 train loss : 4.652385830879211 valid loss : 19.404909133911133]\n",
      "[0778/1000 train loss : 4.701828718185425 valid loss : 19.192750930786133]\n",
      "[0779/1000 train loss : 4.70461106300354 valid loss : 19.51239585876465]\n",
      "[0780/1000 train loss : 4.647690773010254 valid loss : 19.564884185791016]\n",
      "[0781/1000 train loss : 4.5918790102005005 valid loss : 19.29045295715332]\n",
      "[0782/1000 train loss : 4.682048082351685 valid loss : 19.49071502685547]\n",
      "[0783/1000 train loss : 4.651460528373718 valid loss : 19.476158142089844]\n",
      "[0784/1000 train loss : 4.6260459423065186 valid loss : 19.400083541870117]\n",
      "[0785/1000 train loss : 4.700740575790405 valid loss : 19.279582977294922]\n",
      "[0786/1000 train loss : 4.6612138748168945 valid loss : 19.57992172241211]\n",
      "[0787/1000 train loss : 4.622819423675537 valid loss : 19.32866096496582]\n",
      "[0788/1000 train loss : 4.693376064300537 valid loss : 19.27211570739746]\n",
      "[0789/1000 train loss : 4.779430150985718 valid loss : 19.073408126831055]\n",
      "[0790/1000 train loss : 4.625423908233643 valid loss : 19.425634384155273]\n",
      "[0791/1000 train loss : 4.699766635894775 valid loss : 19.462080001831055]\n",
      "[0792/1000 train loss : 4.643512964248657 valid loss : 19.449129104614258]\n",
      "[0793/1000 train loss : 4.631194591522217 valid loss : 19.345293045043945]\n",
      "[0794/1000 train loss : 4.755733251571655 valid loss : 19.314416885375977]\n",
      "[0795/1000 train loss : 4.711147308349609 valid loss : 19.08860969543457]\n",
      "[0796/1000 train loss : 4.586195230484009 valid loss : 19.487213134765625]\n",
      "[0797/1000 train loss : 4.633380651473999 valid loss : 19.237606048583984]\n",
      "[0798/1000 train loss : 4.598065614700317 valid loss : 19.42763900756836]\n",
      "[0799/1000 train loss : 4.553148865699768 valid loss : 19.403749465942383]\n",
      "[0800/1000 train loss : 4.584943771362305 valid loss : 19.531219482421875]\n",
      "[0801/1000 train loss : 4.514695405960083 valid loss : 19.587587356567383]\n",
      "[0802/1000 train loss : 4.578311204910278 valid loss : 19.666696548461914]\n",
      "[0803/1000 train loss : 4.683221817016602 valid loss : 19.54645347595215]\n",
      "[0804/1000 train loss : 4.528276562690735 valid loss : 19.462745666503906]\n",
      "[0805/1000 train loss : 4.588398218154907 valid loss : 19.21392059326172]\n",
      "[0806/1000 train loss : 4.519104957580566 valid loss : 19.41176414489746]\n",
      "[0807/1000 train loss : 4.252458810806274 valid loss : 19.477630615234375]\n",
      "[0808/1000 train loss : 4.538874864578247 valid loss : 19.218807220458984]\n",
      "[0809/1000 train loss : 4.499854326248169 valid loss : 19.36336898803711]\n",
      "[0810/1000 train loss : 4.539589524269104 valid loss : 19.375619888305664]\n",
      "[0811/1000 train loss : 4.60515570640564 valid loss : 19.332765579223633]\n",
      "[0812/1000 train loss : 4.746097803115845 valid loss : 19.712108612060547]\n",
      "[0813/1000 train loss : 4.5358054637908936 valid loss : 19.420244216918945]\n",
      "[0814/1000 train loss : 4.518163442611694 valid loss : 19.467302322387695]\n",
      "[0815/1000 train loss : 4.568589687347412 valid loss : 19.540058135986328]\n",
      "[0816/1000 train loss : 4.551030397415161 valid loss : 19.21584701538086]\n",
      "[0817/1000 train loss : 4.60650897026062 valid loss : 19.075895309448242]\n",
      "[0818/1000 train loss : 4.537740230560303 valid loss : 19.13141632080078]\n",
      "[0819/1000 train loss : 4.520275115966797 valid loss : 19.17388343811035]\n",
      "[0820/1000 train loss : 4.537052869796753 valid loss : 19.2405948638916]\n",
      "[0821/1000 train loss : 4.518799066543579 valid loss : 19.626874923706055]\n",
      "[0822/1000 train loss : 4.4513009786605835 valid loss : 19.203567504882812]\n",
      "[0823/1000 train loss : 4.492802143096924 valid loss : 19.4107723236084]\n",
      "[0824/1000 train loss : 4.3871766328811646 valid loss : 19.288740158081055]\n",
      "[0825/1000 train loss : 4.515429496765137 valid loss : 19.409456253051758]\n",
      "[0826/1000 train loss : 4.541311025619507 valid loss : 19.1978702545166]\n",
      "[0827/1000 train loss : 4.649003744125366 valid loss : 19.45258331298828]\n",
      "[0828/1000 train loss : 4.518064737319946 valid loss : 19.378419876098633]\n",
      "[0829/1000 train loss : 4.423182964324951 valid loss : 19.22270965576172]\n",
      "[0830/1000 train loss : 4.460667371749878 valid loss : 19.314577102661133]\n",
      "[0831/1000 train loss : 4.538618564605713 valid loss : 19.498092651367188]\n",
      "[0832/1000 train loss : 4.445309638977051 valid loss : 19.306900024414062]\n",
      "[0833/1000 train loss : 4.421677350997925 valid loss : 19.245344161987305]\n",
      "[0834/1000 train loss : 4.471232891082764 valid loss : 19.227100372314453]\n",
      "[0835/1000 train loss : 4.47162389755249 valid loss : 19.473169326782227]\n",
      "[0836/1000 train loss : 4.291008234024048 valid loss : 19.002391815185547]\n",
      "[0837/1000 train loss : 4.466696500778198 valid loss : 19.42810821533203]\n",
      "[0838/1000 train loss : 4.454843282699585 valid loss : 19.513412475585938]\n",
      "[0839/1000 train loss : 4.399740219116211 valid loss : 19.183225631713867]\n",
      "[0840/1000 train loss : 4.415086269378662 valid loss : 19.167556762695312]\n",
      "[0841/1000 train loss : 4.378958463668823 valid loss : 19.127120971679688]\n",
      "[0842/1000 train loss : 4.3594818115234375 valid loss : 19.345869064331055]\n",
      "[0843/1000 train loss : 4.39502215385437 valid loss : 19.381824493408203]\n",
      "[0844/1000 train loss : 4.380826473236084 valid loss : 19.366933822631836]\n",
      "[0845/1000 train loss : 4.368771314620972 valid loss : 19.12451934814453]\n",
      "[0846/1000 train loss : 4.375487804412842 valid loss : 19.080673217773438]\n",
      "[0847/1000 train loss : 4.414403200149536 valid loss : 19.442049026489258]\n",
      "[0848/1000 train loss : 4.471036672592163 valid loss : 19.435516357421875]\n",
      "[0849/1000 train loss : 4.486359596252441 valid loss : 19.036636352539062]\n",
      "[0850/1000 train loss : 4.377254962921143 valid loss : 19.213470458984375]\n",
      "[0851/1000 train loss : 4.40435266494751 valid loss : 19.12432289123535]\n",
      "[0852/1000 train loss : 4.323314428329468 valid loss : 19.11702537536621]\n",
      "[0853/1000 train loss : 4.346440076828003 valid loss : 19.210514068603516]\n",
      "[0854/1000 train loss : 4.441877126693726 valid loss : 18.912460327148438]\n",
      "[0855/1000 train loss : 4.461112141609192 valid loss : 19.036893844604492]\n",
      "[0856/1000 train loss : 4.350815415382385 valid loss : 19.338098526000977]\n",
      "[0857/1000 train loss : 4.354946613311768 valid loss : 19.239477157592773]\n",
      "[0858/1000 train loss : 4.35425329208374 valid loss : 19.34111213684082]\n",
      "[0859/1000 train loss : 4.386287212371826 valid loss : 19.152917861938477]\n",
      "[0860/1000 train loss : 4.486473560333252 valid loss : 19.4924259185791]\n",
      "[0861/1000 train loss : 4.278157711029053 valid loss : 18.940372467041016]\n",
      "[0862/1000 train loss : 4.2866432666778564 valid loss : 18.940837860107422]\n",
      "[0863/1000 train loss : 4.37699818611145 valid loss : 19.003833770751953]\n",
      "[0864/1000 train loss : 4.36926531791687 valid loss : 19.083467483520508]\n",
      "[0865/1000 train loss : 4.390319585800171 valid loss : 19.030569076538086]\n",
      "[0866/1000 train loss : 4.331314444541931 valid loss : 19.130863189697266]\n",
      "[0867/1000 train loss : 4.2291038036346436 valid loss : 19.209129333496094]\n",
      "[0868/1000 train loss : 4.3104517459869385 valid loss : 19.196704864501953]\n",
      "[0869/1000 train loss : 4.298757314682007 valid loss : 19.008079528808594]\n",
      "[0870/1000 train loss : 4.30757212638855 valid loss : 19.19126319885254]\n",
      "[0871/1000 train loss : 4.27489972114563 valid loss : 19.013200759887695]\n",
      "[0872/1000 train loss : 4.311850309371948 valid loss : 19.401439666748047]\n",
      "[0873/1000 train loss : 4.304561138153076 valid loss : 19.190378189086914]\n",
      "[0874/1000 train loss : 4.280928134918213 valid loss : 19.158111572265625]\n",
      "[0875/1000 train loss : 4.337242841720581 valid loss : 19.018421173095703]\n",
      "[0876/1000 train loss : 4.327097177505493 valid loss : 19.256792068481445]\n",
      "[0877/1000 train loss : 4.383582830429077 valid loss : 19.271699905395508]\n",
      "[0878/1000 train loss : 4.256788015365601 valid loss : 19.15793228149414]\n",
      "[0879/1000 train loss : 4.25516414642334 valid loss : 19.34819984436035]\n",
      "[0880/1000 train loss : 4.357999801635742 valid loss : 19.126949310302734]\n",
      "[0881/1000 train loss : 4.289759159088135 valid loss : 19.13884735107422]\n",
      "[0882/1000 train loss : 4.319491982460022 valid loss : 19.32821273803711]\n",
      "[0883/1000 train loss : 4.257174015045166 valid loss : 19.339263916015625]\n",
      "[0884/1000 train loss : 4.249438762664795 valid loss : 19.17629051208496]\n",
      "[0885/1000 train loss : 4.212998628616333 valid loss : 19.21634292602539]\n",
      "[0886/1000 train loss : 4.280837297439575 valid loss : 18.94158935546875]\n",
      "[0887/1000 train loss : 4.253661155700684 valid loss : 19.239654541015625]\n",
      "[0888/1000 train loss : 4.279628753662109 valid loss : 19.33059310913086]\n",
      "[0889/1000 train loss : 4.263522624969482 valid loss : 19.27068328857422]\n",
      "[0890/1000 train loss : 4.263790130615234 valid loss : 19.127607345581055]\n",
      "[0891/1000 train loss : 4.2302446365356445 valid loss : 19.0561466217041]\n",
      "[0892/1000 train loss : 4.218015789985657 valid loss : 19.089035034179688]\n",
      "[0893/1000 train loss : 4.229513883590698 valid loss : 19.05408477783203]\n",
      "[0894/1000 train loss : 4.2083985805511475 valid loss : 18.895299911499023]\n",
      "[0895/1000 train loss : 4.194027543067932 valid loss : 18.948814392089844]\n",
      "[0896/1000 train loss : 4.2979841232299805 valid loss : 19.091182708740234]\n",
      "[0897/1000 train loss : 4.224980115890503 valid loss : 19.06475067138672]\n",
      "[0898/1000 train loss : 4.235928773880005 valid loss : 19.32990074157715]\n",
      "[0899/1000 train loss : 4.179776310920715 valid loss : 19.206201553344727]\n",
      "[0900/1000 train loss : 4.220026135444641 valid loss : 19.16399383544922]\n",
      "[0901/1000 train loss : 4.214934229850769 valid loss : 18.941869735717773]\n",
      "[0902/1000 train loss : 4.175313115119934 valid loss : 19.23047637939453]\n",
      "[0903/1000 train loss : 4.119122505187988 valid loss : 19.21736717224121]\n",
      "[0904/1000 train loss : 4.18130087852478 valid loss : 18.95874786376953]\n",
      "[0905/1000 train loss : 4.155284404754639 valid loss : 19.09487533569336]\n",
      "[0906/1000 train loss : 4.0106425285339355 valid loss : 19.31879997253418]\n",
      "[0907/1000 train loss : 4.23135244846344 valid loss : 18.94236946105957]\n",
      "[0908/1000 train loss : 4.160539865493774 valid loss : 19.23679542541504]\n",
      "[0909/1000 train loss : 4.143206596374512 valid loss : 18.910228729248047]\n",
      "[0910/1000 train loss : 4.123617887496948 valid loss : 18.991077423095703]\n",
      "[0911/1000 train loss : 4.156916379928589 valid loss : 19.326213836669922]\n",
      "[0912/1000 train loss : 4.283030152320862 valid loss : 19.207809448242188]\n",
      "[0913/1000 train loss : 4.172783136367798 valid loss : 19.019872665405273]\n",
      "[0914/1000 train loss : 4.120586037635803 valid loss : 19.091554641723633]\n",
      "[0915/1000 train loss : 4.02789580821991 valid loss : 19.0770206451416]\n",
      "[0916/1000 train loss : 4.05007004737854 valid loss : 18.961633682250977]\n",
      "[0917/1000 train loss : 4.123483777046204 valid loss : 18.994253158569336]\n",
      "[0918/1000 train loss : 4.118268966674805 valid loss : 19.029560089111328]\n",
      "[0919/1000 train loss : 4.167803764343262 valid loss : 19.27301788330078]\n",
      "[0920/1000 train loss : 4.168625593185425 valid loss : 19.187753677368164]\n",
      "[0921/1000 train loss : 4.125429272651672 valid loss : 18.84671401977539]\n",
      "[0922/1000 train loss : 4.081608772277832 valid loss : 19.387348175048828]\n",
      "[0923/1000 train loss : 4.201952219009399 valid loss : 19.55860137939453]\n",
      "[0924/1000 train loss : 4.1465232372283936 valid loss : 19.209413528442383]\n",
      "[0925/1000 train loss : 4.16698157787323 valid loss : 19.309539794921875]\n",
      "[0926/1000 train loss : 4.092504978179932 valid loss : 19.17192268371582]\n",
      "[0927/1000 train loss : 4.109812021255493 valid loss : 19.00836753845215]\n",
      "[0928/1000 train loss : 4.089687824249268 valid loss : 19.152685165405273]\n",
      "[0929/1000 train loss : 4.078043222427368 valid loss : 18.880130767822266]\n",
      "[0930/1000 train loss : 4.0495569705963135 valid loss : 19.02427101135254]\n",
      "[0931/1000 train loss : 4.01788330078125 valid loss : 18.8841495513916]\n",
      "[0932/1000 train loss : 4.123781323432922 valid loss : 19.231342315673828]\n",
      "[0933/1000 train loss : 4.134757161140442 valid loss : 19.25506591796875]\n",
      "[0934/1000 train loss : 4.0193703174591064 valid loss : 19.145235061645508]\n",
      "[0935/1000 train loss : 4.07996129989624 valid loss : 19.187898635864258]\n",
      "[0936/1000 train loss : 4.06331729888916 valid loss : 19.006431579589844]\n",
      "[0937/1000 train loss : 4.037562727928162 valid loss : 19.03340721130371]\n",
      "[0938/1000 train loss : 4.096081852912903 valid loss : 19.14646339416504]\n",
      "[0939/1000 train loss : 4.084961533546448 valid loss : 19.16741371154785]\n",
      "[0940/1000 train loss : 4.01257848739624 valid loss : 19.134504318237305]\n",
      "[0941/1000 train loss : 3.9931329488754272 valid loss : 19.108285903930664]\n",
      "[0942/1000 train loss : 4.013635039329529 valid loss : 19.04198455810547]\n",
      "[0943/1000 train loss : 4.114562034606934 valid loss : 18.93211555480957]\n",
      "[0944/1000 train loss : 4.166726589202881 valid loss : 18.79621124267578]\n",
      "[0945/1000 train loss : 4.031457424163818 valid loss : 18.990928649902344]\n",
      "[0946/1000 train loss : 3.9077266454696655 valid loss : 19.12108612060547]\n",
      "[0947/1000 train loss : 3.9971519708633423 valid loss : 19.340482711791992]\n",
      "[0948/1000 train loss : 4.109402179718018 valid loss : 19.316478729248047]\n",
      "[0949/1000 train loss : 3.968102216720581 valid loss : 18.747621536254883]\n",
      "[0950/1000 train loss : 4.06173574924469 valid loss : 19.40868377685547]\n",
      "[0951/1000 train loss : 4.079410791397095 valid loss : 19.0137939453125]\n",
      "[0952/1000 train loss : 3.990017294883728 valid loss : 18.94821548461914]\n",
      "[0953/1000 train loss : 4.024835109710693 valid loss : 18.914243698120117]\n",
      "[0954/1000 train loss : 3.9970215559005737 valid loss : 19.11823272705078]\n",
      "[0955/1000 train loss : 3.9868483543395996 valid loss : 18.99307632446289]\n",
      "[0956/1000 train loss : 4.032976031303406 valid loss : 19.30039405822754]\n",
      "[0957/1000 train loss : 3.986001491546631 valid loss : 19.065696716308594]\n",
      "[0958/1000 train loss : 3.9895730018615723 valid loss : 18.85667610168457]\n",
      "[0959/1000 train loss : 3.962435245513916 valid loss : 19.188251495361328]\n",
      "[0960/1000 train loss : 4.061926960945129 valid loss : 19.049728393554688]\n",
      "[0961/1000 train loss : 4.019863605499268 valid loss : 18.89105987548828]\n",
      "[0962/1000 train loss : 4.019768714904785 valid loss : 18.783313751220703]\n",
      "[0963/1000 train loss : 4.0133092403411865 valid loss : 19.080244064331055]\n",
      "[0964/1000 train loss : 4.011156678199768 valid loss : 19.036087036132812]\n",
      "[0965/1000 train loss : 3.974578380584717 valid loss : 18.87862205505371]\n",
      "[0966/1000 train loss : 3.960565209388733 valid loss : 19.018386840820312]\n",
      "[0967/1000 train loss : 3.9703584909439087 valid loss : 19.045557022094727]\n",
      "[0968/1000 train loss : 4.071750640869141 valid loss : 18.755828857421875]\n",
      "[0969/1000 train loss : 3.924265503883362 valid loss : 18.937740325927734]\n",
      "[0970/1000 train loss : 4.055291414260864 valid loss : 18.95220184326172]\n",
      "[0971/1000 train loss : 3.9961386919021606 valid loss : 18.84618377685547]\n",
      "[0972/1000 train loss : 3.8812179565429688 valid loss : 18.967361450195312]\n",
      "[0973/1000 train loss : 3.903101325035095 valid loss : 18.92502212524414]\n",
      "[0974/1000 train loss : 3.9091241359710693 valid loss : 18.98280906677246]\n",
      "[0975/1000 train loss : 3.942332148551941 valid loss : 19.216676712036133]\n",
      "[0976/1000 train loss : 3.8709070682525635 valid loss : 18.929420471191406]\n",
      "[0977/1000 train loss : 3.8590567111968994 valid loss : 19.061128616333008]\n",
      "[0978/1000 train loss : 3.859331250190735 valid loss : 19.1972713470459]\n",
      "[0979/1000 train loss : 3.902219772338867 valid loss : 18.886625289916992]\n",
      "[0980/1000 train loss : 3.9027674198150635 valid loss : 19.074487686157227]\n",
      "[0981/1000 train loss : 3.8919235467910767 valid loss : 18.91912269592285]\n",
      "[0982/1000 train loss : 3.8482370376586914 valid loss : 19.142560958862305]\n",
      "[0983/1000 train loss : 3.8733420372009277 valid loss : 18.923965454101562]\n",
      "[0984/1000 train loss : 3.840553879737854 valid loss : 18.990482330322266]\n",
      "[0985/1000 train loss : 3.88097083568573 valid loss : 19.35689353942871]\n",
      "[0986/1000 train loss : 3.83807373046875 valid loss : 19.117815017700195]\n",
      "[0987/1000 train loss : 3.9178640842437744 valid loss : 19.075298309326172]\n",
      "[0988/1000 train loss : 3.914495825767517 valid loss : 18.961999893188477]\n",
      "[0989/1000 train loss : 3.8379404544830322 valid loss : 19.012712478637695]\n",
      "[0990/1000 train loss : 3.8420658111572266 valid loss : 18.981576919555664]\n",
      "[0991/1000 train loss : 3.8598520755767822 valid loss : 19.088783264160156]\n",
      "[0992/1000 train loss : 3.8166552782058716 valid loss : 19.191255569458008]\n",
      "[0993/1000 train loss : 3.84203565120697 valid loss : 18.926755905151367]\n",
      "[0994/1000 train loss : 3.92931592464447 valid loss : 18.750749588012695]\n",
      "[0995/1000 train loss : 3.8585394620895386 valid loss : 18.964109420776367]\n",
      "[0996/1000 train loss : 3.762869715690613 valid loss : 18.667451858520508]\n",
      "[0997/1000 train loss : 3.879987597465515 valid loss : 18.881900787353516]\n",
      "[0998/1000 train loss : 3.833447575569153 valid loss : 18.924365997314453]\n",
      "[0999/1000 train loss : 3.8892775774002075 valid loss : 18.883087158203125]\n",
      "[1000/1000 train loss : 3.88476026058197 valid loss : 19.04169273376465]\n",
      "학습에 걸린 시간: -14.627131462097168초\n"
     ]
    }
   ],
   "source": [
    "# train + evalutation\n",
    "\n",
    "import time \n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "\n",
    "# 1 epoch 학습 2 단계 : train(train_loader) -> 검증(test_loader)\n",
    "s= time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # epoch별 처리 \n",
    "    ############################\n",
    "    # 학습\n",
    "    ############################\n",
    "    # 1. train 모드 변경\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_train, y_train in train_loader: # batch 단위로 학습\n",
    "        # 한 step 학습 \n",
    "        # 1. device로 옮기기\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        # 2. 모델 추정 \n",
    "        pred_train = model(X_train)\n",
    "        # 3. loss 계산\n",
    "        loss = loss_fn(pred_train, y_train)\n",
    "        # 4. loss 기준 gradient 계산 \n",
    "        loss.backward()\n",
    "        # 5. 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "        # 6. 파라미터 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 7. 로그출력을 위한 loss 누적\n",
    "        train_loss += loss.item() # batch의 loss 누적\n",
    "    train_loss/=len(train_loader) # epoch별 train_loss 평균\n",
    "    \n",
    "    ############################\n",
    "    # 검증\n",
    "    ############################\n",
    "    # 1. eval 모드 변경\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in test_loader:\n",
    "            #1. device로 옮기기 \n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            #2. 모델 추정 \n",
    "            pred_val = model(X_val)\n",
    "            #3. 검증\n",
    "            loss = loss_fn(pred_val, y_val)\n",
    "            # 4. batch별 loss 누적\n",
    "            valid_loss += loss.item()\n",
    "        valid_loss /= len(test_loader)\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "\n",
    "    print(f\"[{epoch+1:04d}/{EPOCHS} train loss : {train_loss} valid loss : {valid_loss}]\")\n",
    "\n",
    "\n",
    "e= time.time()\n",
    "print(f\"학습에 걸린 시간: {s-e}초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2a294183-5ebf-485d-b4db-1c9572434d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 학습 결과 시각화\n",
    "\n",
    "plt.figure(figsize = (8,5))\n",
    "plt.plot(range(EPOCHS), train_loss_list, label = \"Train loss\")\n",
    "plt.plot(range(EPOCHS), valid_loss_list, label = \"Valid loss\")\n",
    "plt.grid(True, linestyle=\":\")\n",
    "plt.ylim(0,50)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "93777e03-60b8-4857-8014-a71859d37b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 저장 \n",
    "boston_model_save_path = \"saved_models/boston_model.pth\"\n",
    "torch.save(model, boston_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "800d5f90-1a6d-4a0c-9f33-a5c6f4ebebbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BostonModel(\n",
      "  (lr1): Linear(in_features=13, out_features=32, bias=True)\n",
      "  (lr2): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (lr3): Linear(in_features=16, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### 저장된 모델 로드\n",
    "load_model = torch.load(boston_model_save_path)\n",
    "print(load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5e72653d-8c1a-48b6-bb9a-43985a9e8341",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 새로운 데이터 추정 \n",
    "new_data= torch.tensor(X_test_scaled[:5])\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_hat = load_model(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8625798b-3c3e-4743-b441-5cf23f70c8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.6],\n",
       "       [50. ],\n",
       "       [23. ],\n",
       "       [ 8.3],\n",
       "       [21.2]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "913e9ed4-87a9-42e2-8439-d0e4f7a11a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.9891],\n",
       "        [27.5494],\n",
       "        [23.5253],\n",
       "        [11.0426],\n",
       "        [17.6864]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae53fb45-50a8-4aae-9a28-626487fff0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
